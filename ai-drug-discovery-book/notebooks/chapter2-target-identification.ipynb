{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adcfbe8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CID: 2244, Connectivity SMILES: CC(=O)OC1=CC=CC=C1C(=O)O\n"
     ]
    }
   ],
   "source": [
    "# Example: Fetching connectivity SMILES from PubChemPy (no deprecation warning)\n",
    "import pubchempy as pcp\n",
    "\n",
    "compounds = pcp.get_compounds('aspirin', 'name')\n",
    "for c in compounds:\n",
    "    print(f\"CID: {c.cid}, Connectivity SMILES: {c.connectivity_smiles}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12646684",
   "metadata": {},
   "source": [
    "## Check for Existing Notebooks\n",
    "\n",
    "Let's search the current directory for Jupyter notebook files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c70d696f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebooks in this directory: ['chapter3-cheminformatics-essentials.ipynb', 'sample_generated_notebook.ipynb', 'chapter1-genomics-to-molecules.ipynb', 'chapter4-compound-screening.ipynb', 'chapter5-ml-for-drug-discovery.ipynb', 'chapter2-target-identification.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List all .ipynb files in the current directory\n",
    "notebooks = [f for f in os.listdir('.') if f.endswith('.ipynb')]\n",
    "print(\"Notebooks in this directory:\", notebooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc03314",
   "metadata": {},
   "source": [
    "## Generate a New Notebook File\n",
    "\n",
    "You can programmatically create a new Jupyter notebook using the `nbformat` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3ab1d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created sample_generated_notebook.ipynb\n"
     ]
    }
   ],
   "source": [
    "import nbformat as nbf\n",
    "\n",
    "nb = nbf.v4.new_notebook()\n",
    "nb['cells'] = [nbf.v4.new_code_cell(\"print('Hello, new notebook!')\")]\n",
    "with open('sample_generated_notebook.ipynb', 'w') as f:\n",
    "    nbf.write(nb, f)\n",
    "print(\"Created sample_generated_notebook.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970a8430",
   "metadata": {},
   "source": [
    "## List All Notebooks in the Directory\n",
    "\n",
    "Let's display all `.ipynb` files in the current directory again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8adb1d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebooks in this directory: ['chapter3-cheminformatics-essentials.ipynb', 'sample_generated_notebook.ipynb', 'chapter1-genomics-to-molecules.ipynb', 'chapter4-compound-screening.ipynb', 'chapter5-ml-for-drug-discovery.ipynb', 'chapter2-target-identification.ipynb']\n"
     ]
    }
   ],
   "source": [
    "# List all .ipynb files again\n",
    "notebooks = [f for f in os.listdir('.') if f.endswith('.ipynb')]\n",
    "print(\"Notebooks in this directory:\", notebooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b79a1a",
   "metadata": {},
   "source": [
    "## Open a Notebook in Visual Studio Code\n",
    "\n",
    "You can open a notebook from the terminal using:\n",
    "\n",
    "```bash\n",
    "code chapter2-target-identification.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4527bddb",
   "metadata": {},
   "source": [
    "## Run Code Cells Programmatically\n",
    "\n",
    "You can execute notebook cells programmatically using `nbconvert` or `papermill`. Example with papermill:\n",
    "\n",
    "```python\n",
    "import papermill as pm\n",
    "pm.execute_notebook('chapter2-target-identification.ipynb', 'output.ipynb')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7861dde",
   "metadata": {},
   "source": [
    "## Practical Target Identification Examples\n",
    "\n",
    "Below are three hands-on code examples for target identification using NLP and public databases. Each example includes an explanation to help you understand the workflow and its relevance to drug discovery.\n",
    "\n",
    "1. **NER on Custom Biomedical Text:** Use a pretrained NLP model to extract gene/protein names (potential drug targets) from biomedical sentences.\n",
    "2. **Automated PubMed Search and NER:** Search PubMed for disease-related abstracts, then use NER to extract targets from real literature.\n",
    "3. **UniProt Query for Target Information:** Query UniProt for detailed information about a gene/protein target identified in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98fe41ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping import of cpp extensions due to incompatible torch version 2.9.1 for torchao version 0.13.0\n",
      "W1127 14:55:11.293000 72956 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities: [{'entity_group': 'ORG', 'score': np.float32(0.56968904), 'word': 'AP', 'start': 0, 'end': 2}, {'entity_group': 'MISC', 'score': np.float32(0.67893267), 'word': 'BACE', 'start': 8, 'end': 12}, {'entity_group': 'MISC', 'score': np.float32(0.90901405), 'word': 'Alzheimer', 'start': 33, 'end': 42}]\n"
     ]
    }
   ],
   "source": [
    "# 1. NER on Custom Biomedical Text\n",
    "from transformers import pipeline\n",
    "\n",
    "# Use a public general NER model\n",
    "nlp = pipeline(\"ner\", model=\"dslim/bert-base-NER\", aggregation_strategy=\"simple\")\n",
    "text = \"APP and BACE1 are key targets in Alzheimer's disease.\"\n",
    "results = nlp(text)\n",
    "print(\"Named Entities:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7730bf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract:\n",
      " 1. Neurol Ther. 2025 Nov 27. doi: 10.1007/s40120-025-00869-w. Online ahead of \n",
      "print.\n",
      "\n",
      "Care Partners' Perceptions of Amyloid-Targeting Therapy and Treat‑to‑Clearance \n",
      "for Alzheimer's Disease in Japan: A Qualitative Study.\n",
      "\n",
      "Katayama S(1), Tsujimoto M(2), Suzuki K(2), Ueda K(3), Shimoura K(4), Suo S(4), \n",
      "Hatakeyama N(5).\n",
      "\n",
      "Author information:\n",
      "(1)Katayama Medical Clinic, Matsuda Parking Building 1F, 1-26, Kotobuki-cho, \n",
      "Kurashiki-shi, Okayama, 710-0813, Japan.\n",
      "(2)Innovation Center for Translational Research, National Center for Geriatrics \n",
      "and Gerontology, 7-430 Morioka-cho, Obu-shi, Aichi, 474-8511, Japan.\n",
      "(3)Eli Lilly Japan K.K., LILLY PLAZA ONE BLDG, 5-1-28, Isogami-dori, Chuo-ku, \n",
      "Kobe-shi, Hyogo, 651-0086, Japan. ueda_kaname@lilly.com.\n",
      "(4)Mebix, Inc., 1-11-44 Akasaka, Minato-ku, Tokyo, 107-0052, Japan.\n",
      "(5)Eli Lilly Japan K.K., LILLY PLAZA ONE BLDG, 5-1-28, Isogami-dori, Chuo-ku, \n",
      "Kobe-shi, Hyogo, 651-0086, Japan.\n",
      "\n",
      "INTRODUCTION: Donanemab has been developed as an amyloid-targeting therapy (ATT) \n",
      "for mild cognitive impairment (MCI) and mild dementia due to Alzheimer's disease \n",
      "(AD). In registration trials involving donanemab, a treat‑to‑clearance approach \n",
      "was used, in which patients discontinued ATT when amyloid plaque levels \n",
      "decreased below a predefined threshold, which differs from previously available \n",
      "symptomatic treatments for AD. Our study explored care partners' perceptions \n",
      "regarding ATT and treat‑to‑clearance.\n",
      "METHODS: This was a cross-sectional, qualitative interview study. Care partners \n",
      "of individuals with MCI or mild dementia due to AD participated in online \n",
      "semi-structured interviews about their perceptions regarding the impact of MCI \n",
      "or mild dementia diagnoses due to AD, the burden of supporting, and \n",
      "use/cessation of ATT. The qualitative data from the interviews were analyzed \n",
      "using a thematic approach.\n",
      "RESULTS: The participants were 22 care partners (5 male/17 female), and their \n",
      "median age was 59 (range 35-81) years. The most common relationships between \n",
      "care partners and the individuals with AD were child (50.0%) and spouse/partner \n",
      "(45.5%); 68.2% of the care partners lived with the individuals with AD. Thematic \n",
      "analysis identified three major classifications (Thoughts regarding therapy; \n",
      "Treat‑to‑clearance; and Burdens of support), along with 15 themes and five \n",
      "sub-themes. Care partners expressed experiencing mental burden and time \n",
      "constraints, while treat‑to‑clearance could save care partners' time by reducing \n",
      "hospital waiting time and alleviating financial burden. Confirming the clearance \n",
      "of amyloid β plaques provided care partners with a sense of relief, while they \n",
      "remained concerned about the potential progression of AD symptoms and sought \n",
      "follow-up care after stopping treatment.\n",
      "CONCLUSIONS: These results suggest that providing clear explanations and \n",
      "facilitating shared decision-making when introducing ATT, as well as introducing \n",
      "follow-up care and long-term evidence after stopping treatment, are needed.\n",
      "\n",
      "© 2025. The Author(s).\n",
      "\n",
      "DOI: 10.1007/s40120-025-00869-w\n",
      "PMID: 41307609\n",
      "\n",
      "Conflict of interest statement: Declarations. Conflict of Interest: Sadao \n",
      "Katayama received consultancy fees from Eisai Co. Ltd. Kanako Shimoura and \n",
      "Shintaro Suo are employees of Mebix, Inc, which was outsourced by Eli Lilly and \n",
      "Company to perform this study. Kaname Ueda and Naohisa Hatakeyama are employees \n",
      "of Eli Lilly Japan K.K. and hold shares in Eli Lilly and Company. Masashi \n",
      "Tsujimoto and Keisuke Suzuki have no conflict of interest to declare. Ethical \n",
      "Approval: This study was conducted in accordance with the Declaration of \n",
      "Helsinki, Ethical Guidelines for Medical and Biological Research involving Human \n",
      "Subjects, and Japanese laws and regulations, and was approved by the Takahashi \n",
      "Clinic Ethics Committee (LNW00216). To enroll in this study, all participants \n",
      "were asked for and provided written informed consent. All of the data collected \n",
      "were processed and stored in accordance with the law on the protection of \n",
      "personal information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities: [{'entity_group': 'ORG', 'score': np.float32(0.99550205), 'word': 'N', 'start': 3, 'end': 4}, {'entity_group': 'ORG', 'score': np.float32(0.9862751), 'word': '##eurol Ther', 'start': 4, 'end': 14}, {'entity_group': 'ORG', 'score': np.float32(0.99838954), 'word': 'Care Partners', 'start': 87, 'end': 100}, {'entity_group': 'MISC', 'score': np.float32(0.6516541), 'word': '##id', 'start': 122, 'end': 124}, {'entity_group': 'MISC', 'score': np.float32(0.85668623), 'word': \"Alzheimer ' s Disease\", 'start': 171, 'end': 190}, {'entity_group': 'LOC', 'score': np.float32(0.9992847), 'word': 'Japan', 'start': 194, 'end': 199}, {'entity_group': 'PER', 'score': np.float32(0.83307457), 'word': 'Kat', 'start': 223, 'end': 226}, {'entity_group': 'ORG', 'score': np.float32(0.7528863), 'word': '##aya', 'start': 226, 'end': 229}, {'entity_group': 'PER', 'score': np.float32(0.6599837), 'word': 'S', 'start': 232, 'end': 233}, {'entity_group': 'PER', 'score': np.float32(0.9979234), 'word': 'T', 'start': 238, 'end': 239}, {'entity_group': 'PER', 'score': np.float32(0.7425327), 'word': '##sujimoto', 'start': 239, 'end': 247}, {'entity_group': 'PER', 'score': np.float32(0.7524648), 'word': 'Suzuki K', 'start': 254, 'end': 262}, {'entity_group': 'PER', 'score': np.float32(0.9957287), 'word': 'U', 'start': 267, 'end': 268}, {'entity_group': 'PER', 'score': np.float32(0.92682576), 'word': '##eda K', 'start': 268, 'end': 273}, {'entity_group': 'PER', 'score': np.float32(0.9956995), 'word': 'Shi', 'start': 278, 'end': 281}, {'entity_group': 'PER', 'score': np.float32(0.8650517), 'word': 'K', 'start': 287, 'end': 288}, {'entity_group': 'PER', 'score': np.float32(0.9956151), 'word': 'Su', 'start': 293, 'end': 295}, {'entity_group': 'PER', 'score': np.float32(0.90176445), 'word': 'S', 'start': 297, 'end': 298}, {'entity_group': 'PER', 'score': np.float32(0.99591833), 'word': 'Hat', 'start': 304, 'end': 307}, {'entity_group': 'ORG', 'score': np.float32(0.49496213), 'word': 'Kat', 'start': 345, 'end': 348}, {'entity_group': 'LOC', 'score': np.float32(0.77782667), 'word': '##ayama Medical Clinic', 'start': 348, 'end': 368}, {'entity_group': 'LOC', 'score': np.float32(0.8405557), 'word': 'Matsuda Parking Building', 'start': 370, 'end': 394}, {'entity_group': 'PER', 'score': np.float32(0.77654207), 'word': 'Ko', 'start': 405, 'end': 407}, {'entity_group': 'LOC', 'score': np.float32(0.36853564), 'word': '##to', 'start': 407, 'end': 409}, {'entity_group': 'LOC', 'score': np.float32(0.56982976), 'word': 'Kurashiki', 'start': 420, 'end': 429}, {'entity_group': 'LOC', 'score': np.float32(0.5531356), 'word': 's', 'start': 430, 'end': 431}, {'entity_group': 'LOC', 'score': np.float32(0.9918767), 'word': 'Okay', 'start': 435, 'end': 439}, {'entity_group': 'LOC', 'score': np.float32(0.5648998), 'word': '##ama', 'start': 439, 'end': 442}, {'entity_group': 'LOC', 'score': np.float32(0.99948263), 'word': 'Japan', 'start': 454, 'end': 459}, {'entity_group': 'ORG', 'score': np.float32(0.9830262), 'word': 'Innovation Center for Translational Research', 'start': 464, 'end': 508}, {'entity_group': 'ORG', 'score': np.float32(0.9329758), 'word': 'National Center for Geriatrics and Gerontology', 'start': 510, 'end': 557}, {'entity_group': 'LOC', 'score': np.float32(0.75499964), 'word': 'Mo', 'start': 565, 'end': 567}, {'entity_group': 'LOC', 'score': np.float32(0.81733996), 'word': '##rioka', 'start': 567, 'end': 572}, {'entity_group': 'LOC', 'score': np.float32(0.5350147), 'word': 'ch', 'start': 573, 'end': 575}, {'entity_group': 'LOC', 'score': np.float32(0.92238003), 'word': 'Obu', 'start': 578, 'end': 581}, {'entity_group': 'LOC', 'score': np.float32(0.71726334), 'word': 'shi', 'start': 582, 'end': 585}, {'entity_group': 'LOC', 'score': np.float32(0.99448174), 'word': 'Aichi', 'start': 587, 'end': 592}, {'entity_group': 'LOC', 'score': np.float32(0.9992761), 'word': 'Japan', 'start': 604, 'end': 609}, {'entity_group': 'ORG', 'score': np.float32(0.9502723), 'word': 'Eli Lilly Japan K', 'start': 614, 'end': 631}, {'entity_group': 'LOC', 'score': np.float32(0.9719957), 'word': 'K', 'start': 632, 'end': 633}, {'entity_group': 'ORG', 'score': np.float32(0.583364), 'word': 'LILL', 'start': 636, 'end': 640}, {'entity_group': 'ORG', 'score': np.float32(0.6292561), 'word': 'PLAZ', 'start': 642, 'end': 646}, {'entity_group': 'PER', 'score': np.float32(0.71111065), 'word': 'Isoga', 'start': 666, 'end': 671}, {'entity_group': 'PER', 'score': np.float32(0.4083787), 'word': 'do', 'start': 674, 'end': 676}, {'entity_group': 'PER', 'score': np.float32(0.7192492), 'word': 'Chu', 'start': 680, 'end': 683}, {'entity_group': 'LOC', 'score': np.float32(0.9283673), 'word': 'Kobe', 'start': 690, 'end': 694}, {'entity_group': 'LOC', 'score': np.float32(0.54103065), 'word': 's', 'start': 695, 'end': 696}, {'entity_group': 'LOC', 'score': np.float32(0.97564065), 'word': 'H', 'start': 700, 'end': 701}, {'entity_group': 'LOC', 'score': np.float32(0.88245916), 'word': '##yogo', 'start': 701, 'end': 705}, {'entity_group': 'LOC', 'score': np.float32(0.99867165), 'word': 'Japan', 'start': 717, 'end': 722}, {'entity_group': 'ORG', 'score': np.float32(0.9983438), 'word': 'Mebix, Inc', 'start': 750, 'end': 760}, {'entity_group': 'LOC', 'score': np.float32(0.8770913), 'word': 'A', 'start': 771, 'end': 772}, {'entity_group': 'LOC', 'score': np.float32(0.80864024), 'word': '##kasaka', 'start': 772, 'end': 778}, {'entity_group': 'LOC', 'score': np.float32(0.9787131), 'word': 'Minato', 'start': 780, 'end': 786}, {'entity_group': 'LOC', 'score': np.float32(0.5633445), 'word': 'k', 'start': 787, 'end': 788}, {'entity_group': 'LOC', 'score': np.float32(0.9986349), 'word': 'Tokyo', 'start': 791, 'end': 796}, {'entity_group': 'LOC', 'score': np.float32(0.9996617), 'word': 'Japan', 'start': 808, 'end': 813}, {'entity_group': 'ORG', 'score': np.float32(0.998471), 'word': 'Eli Lilly Japan', 'start': 818, 'end': 833}, {'entity_group': 'LOC', 'score': np.float32(0.753515), 'word': 'K', 'start': 834, 'end': 835}, {'entity_group': 'LOC', 'score': np.float32(0.97377807), 'word': 'K', 'start': 836, 'end': 837}, {'entity_group': 'LOC', 'score': np.float32(0.41988745), 'word': 'L', 'start': 840, 'end': 841}, {'entity_group': 'ORG', 'score': np.float32(0.45874283), 'word': '##L', 'start': 843, 'end': 844}, {'entity_group': 'ORG', 'score': np.float32(0.7087354), 'word': 'P', 'start': 846, 'end': 847}, {'entity_group': 'LOC', 'score': np.float32(0.30418238), 'word': '##LA', 'start': 847, 'end': 849}, {'entity_group': 'ORG', 'score': np.float32(0.3798313), 'word': '##Z', 'start': 849, 'end': 850}, {'entity_group': 'PER', 'score': np.float32(0.7010226), 'word': 'Isoga', 'start': 870, 'end': 875}, {'entity_group': 'PER', 'score': np.float32(0.96006477), 'word': 'Chu', 'start': 884, 'end': 887}, {'entity_group': 'LOC', 'score': np.float32(0.9814997), 'word': 'Kobe', 'start': 894, 'end': 898}, {'entity_group': 'LOC', 'score': np.float32(0.73345274), 'word': 's', 'start': 899, 'end': 900}, {'entity_group': 'LOC', 'score': np.float32(0.99671704), 'word': 'Japan', 'start': 921, 'end': 926}, {'entity_group': 'ORG', 'score': np.float32(0.54838336), 'word': 'MC', 'start': 1042, 'end': 1044}, {'entity_group': 'MISC', 'score': np.float32(0.7359879), 'word': 'AD', 'start': 1094, 'end': 1096}, {'entity_group': 'MISC', 'score': np.float32(0.5293378), 'word': 'AD', 'start': 1355, 'end': 1357}]\n"
     ]
    }
   ],
   "source": [
    "# 2. Automated PubMed Search and NER\n",
    "from Bio import Entrez\n",
    "from transformers import pipeline\n",
    "\n",
    "Entrez.email = \"justinzhang.xl@gmail.com\"  # Replace with your email\n",
    "\n",
    "# Search PubMed for abstracts related to Alzheimer's targets\n",
    "handle = Entrez.esearch(db=\"pubmed\", term=\"Alzheimer target\", retmax=1)\n",
    "record = Entrez.read(handle)\n",
    "pubmed_ids = record[\"IdList\"]\n",
    "\n",
    "# Fetch the abstract text\n",
    "if pubmed_ids:\n",
    "    fetch_handle = Entrez.efetch(db=\"pubmed\", id=pubmed_ids[0], rettype=\"abstract\", retmode=\"text\")\n",
    "    abstract = fetch_handle.read()\n",
    "    print(\"Abstract:\\n\", abstract)\n",
    "    # Run NER on the abstract using a public general NER model\n",
    "    nlp = pipeline(\"ner\", model=\"dslim/bert-base-NER\", aggregation_strategy=\"simple\")\n",
    "    entities = nlp(abstract)\n",
    "    print(\"Named Entities:\", entities)\n",
    "else:\n",
    "    print(\"No PubMed results found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b9bd523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for P05067 (UniProt):\n",
      "Entry\tProtein names\tGene Names\tOrganism\tLength\n",
      "P05067\tAmyloid-beta precursor protein (APP) (ABPP) (APPI) (Alzheimer disease amyloid A4 protein homolog) (Alzheimer disease amyloid protein) (Amyloid precursor protein) (Amyloid-beta (A4) precursor protein) (Amyloid-beta A4 protein) (Cerebral vascular amyloid peptide) (CVAP) (PreA4) (Protease nexin-II) (PN-II) [Cleaved into: N-APP; Soluble APP-alpha (S-APP-alpha); Soluble APP-beta (S-APP-beta); C99 (Beta-secretase C-terminal fragment) (Beta-CTF); Amyloid-beta protein 42 (Abeta42) (Beta-APP42); Amyloid-beta protein 40 (Abeta40) (Beta-APP40); C83 (Alpha-secretase C-terminal fragment) (Alpha-CTF); P3(42); P3(40); C80; Gamma-secretase C-terminal fragment 59 (Amyloid intracellular domain 59) (AICD-59) (AID(59)) (Gamma-CTF(59)); Gamma-secretase C-terminal fragment 57 (Amyloid intracellular domain 57) (AICD-57) (AID(57)) (Gamma-CTF(57)); Gamma-secretase C-terminal fragment 50 (Amyloid intracellular domain 50) (AICD-50) (AID(50)) (Gamma-CTF(50)); C31]\tAPP A4 AD1\tHomo sapiens (Human)\t770\n",
      "\n",
      "Results for P56817 (UniProt):\n",
      "Entry\tProtein names\tGene Names\tOrganism\tLength\n",
      "P56817\tBeta-secretase 1 (EC 3.4.23.46) (Aspartyl protease 2) (ASP2) (Asp 2) (Beta-site amyloid precursor protein cleaving enzyme 1) (Beta-site APP cleaving enzyme 1) (Memapsin-2) (Membrane-associated aspartic protease 2)\tBACE1 BACE KIAA1149\tHomo sapiens (Human)\t501\n",
      "\n",
      "Results for P10636 (UniProt):\n",
      "Entry\tProtein names\tGene Names\tOrganism\tLength\n",
      "P10636\tMicrotubule-associated protein tau (Neurofibrillary tangle protein) (Paired helical filament-tau) (PHF-tau)\tMAPT MAPTL MTBT1 TAU\tHomo sapiens (Human)\t758\n",
      "\n",
      "Results for P49768 (UniProt):\n",
      "Entry\tProtein names\tGene Names\tOrganism\tLength\n",
      "P49768\tPresenilin-1 (PS-1) (EC 3.4.23.-) (Protein S182) [Cleaved into: Presenilin-1 NTF subunit; Presenilin-1 CTF subunit; Presenilin-1 CTF12 (PS1-CTF12)]\tPSEN1 AD3 PS1 PSNL1\tHomo sapiens (Human)\t467\n",
      "\n",
      "Results for P49810 (UniProt):\n",
      "Entry\tProtein names\tGene Names\tOrganism\tLength\n",
      "P49810\tPresenilin-2 (PS-2) (EC 3.4.23.-) (AD3LP) (AD5) (E5-1) (STM-2) [Cleaved into: Presenilin-2 NTF subunit; Presenilin-2 CTF subunit]\tPSEN2 AD4 PS2 PSNL2 STM2\tHomo sapiens (Human)\t448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. UniProt Query for Target Information\n",
    "import requests\n",
    "\n",
    "def get_uniprot_by_accession(accession):\n",
    "    url = f\"https://rest.uniprot.org/uniprotkb/{accession}.tsv?fields=accession,protein_name,gene_names,organism_name,length\"\n",
    "    response = requests.get(url)\n",
    "    print(f\"Results for {accession} (UniProt):\\n{response.text}\")\n",
    "\n",
    "# Example: Query UniProt for several Alzheimer's-related targets by accession\n",
    "get_uniprot_by_accession(\"P05067\")  # APP\n",
    "get_uniprot_by_accession(\"P56817\")  # BACE1\n",
    "get_uniprot_by_accession(\"P10636\")  # MAPT\n",
    "get_uniprot_by_accession(\"P49768\")  # PSEN1\n",
    "get_uniprot_by_accession(\"P49810\")  # PSEN2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f79c24",
   "metadata": {},
   "source": [
    "### 1. NER on Custom Biomedical Text\n",
    "This cell uses a pretrained BioBERT model to perform Named Entity Recognition (NER) on a biomedical sentence. NER helps identify gene and protein names mentioned in scientific text, which are potential drug targets. This is a common first step in literature mining for target identification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159f0bbe",
   "metadata": {},
   "source": [
    "### 2. Automated PubMed Search and NER\n",
    "This cell demonstrates how to search PubMed for abstracts related to a disease (e.g., Alzheimer's), retrieve the abstract text, and then use NER to extract gene/protein names. This workflow automates the process of finding and prioritizing new drug targets from the latest scientific literature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e229c58f",
   "metadata": {},
   "source": [
    "### 3. UniProt Query for Target Information\n",
    "This cell shows how to query the UniProt database for detailed information about a gene or protein (such as APP). After identifying a potential target using NER and literature mining, you can use UniProt to learn about its biological function, sequence, and relevance to disease, helping you decide if it is a good candidate for drug development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbc76ea-e4d4-48b8-bb86-0f2999d5dc67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
