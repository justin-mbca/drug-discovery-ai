[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI-Driven Drug Discovery: A Hands-On Guide",
    "section": "",
    "text": "Welcome to the AI Drug Discovery Book! Use the navigation to explore chapters on drug discovery, machine learning, and computational tools.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Home</span>"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "2  Preface",
    "section": "",
    "text": "3 Preface\nWelcome to “AI-Driven Drug Discovery: A Hands-On Guide.” This book is designed for data scientists, bioinformaticians, and machine learning engineers who want to apply their skills to the world of drug discovery. Our goal is to provide a practical, code-first approach to modern computational drug discovery, with real-world examples and hands-on exercises throughout.\nWe hope this book empowers you to make meaningful contributions to the future of medicine.",
    "crumbs": [
      "Part 0: Getting Started",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Preface</span>"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "3  Introduction",
    "section": "",
    "text": "4 Introduction\nArtificial intelligence is revolutionizing drug discovery. This book introduces the key concepts, tools, and workflows that are shaping the future of pharmaceutical research. You will learn how to leverage AI, machine learning, and public biomedical data to accelerate the discovery of new medicines.\nWe begin with foundational concepts and build up to advanced, real-world applications, ensuring you gain both theoretical understanding and practical skills.\n\n\n5 High-Level Overview: Steps of Drug Discovery\nDrug discovery is a multi-stage process that transforms basic research into new medicines. The main steps are:\n\nTarget Identification & Validation\nUnderstanding disease biology and identifying molecular targets (e.g., genes, proteins).\nHit Discovery & Screening\nFinding molecules that interact with the target (e.g., high-throughput or virtual screening).\nLead Optimization\nRefining hits for potency, selectivity, and drug-like properties (e.g., Lipinski’s rules, ADME).\nPreclinical Testing\nAssessing safety and efficacy in vitro and in animal models.\nClinical Trials\nTesting in humans (Phases I–III).\nRegulatory Approval & Post-Market Surveillance\nSubmitting data to agencies (e.g., FDA), monitoring real-world use.\n\nBook Chapter Mapping: - Chapters 1–2: Target identification, genomics, and molecules - Chapters 3–5: Screening, cheminformatics, molecular properties - Chapters 6–10: Optimization, validation, preclinical studies - Chapters 11–14: Clinical trials, regulatory science, post-market studies\nOnline Diagrams and Resources: - Drug Discovery Cycle Schematic (Wikipedia, SVG, open license) - FDA: Drug Development Process Overview - ChEMBL Visualizations - ResearchGate: Drug Discovery and Development Process\nYou can click these links for interactive diagrams and further reading.",
    "crumbs": [
      "Part 0: Getting Started",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1-genomics-to-molecules.html",
    "href": "chapters/chapter1-genomics-to-molecules.html",
    "title": "4  Chapter 1: Genomics to Molecules",
    "section": "",
    "text": "4.1 Workflow Overview\nThis chapter introduces the journey from genomics data to actionable molecular targets in drug discovery. It covers how genetic information is translated into protein targets and how these are linked to small molecules for therapeutic intervention.\nThe following diagram illustrates the overall process from genomics data to actionable molecules in drug discovery:\ngraph TD;\n    classDef light fill:#f9f9f9,stroke:#333,stroke-width:1px;\n    Main[main.py]:::light\n    Crew[agents/multi_agent.py]:::light\n    PubMedTool[tools/pubmed.py]:::light\n    PubChemTool[tools/pubchem.py]:::light\n    DB[db/mongodb.py]:::light\n    DataRaw[data/raw/]:::light\n    DataProcessed[data/processed/]:::light\n    UtilsNode[app/utils/]:::light\n\n    Main --&gt; Crew\n    Crew --&gt; PubMedTool\n    Crew --&gt; PubChemTool\n    PubMedTool --&gt;|fetches| DataRaw\n    PubChemTool --&gt;|fetches| DataRaw\n    Crew --&gt; DB\n    Main --&gt; UtilsNode\n    Crew --&gt; UtilsNode\n    Main --&gt;|returns| Main",
    "crumbs": [
      "Part 0: Getting Started",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 1: Genomics to Molecules</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1-genomics-to-molecules.html#summary",
    "href": "chapters/chapter1-genomics-to-molecules.html#summary",
    "title": "4  Chapter 1: Genomics to Molecules",
    "section": "4.2 Summary",
    "text": "4.2 Summary\nThis workflow demonstrates how to start from a gene (e.g., SOD1 for ALS), find the corresponding protein (UniProt), retrieve known small-molecule ligands (ChEMBL), and analyze their molecular properties. This bridges genomics and cheminformatics, enabling rational drug discovery starting from genetic information.",
    "crumbs": [
      "Part 0: Getting Started",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 1: Genomics to Molecules</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1-genomics-to-molecules.html#key-code-snippets",
    "href": "chapters/chapter1-genomics-to-molecules.html#key-code-snippets",
    "title": "4  Chapter 1: Genomics to Molecules",
    "section": "4.3 Key Code Snippets",
    "text": "4.3 Key Code Snippets",
    "crumbs": [
      "Part 0: Getting Started",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 1: Genomics to Molecules</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1-genomics-to-molecules.html#further-reading",
    "href": "chapters/chapter1-genomics-to-molecules.html#further-reading",
    "title": "4  Chapter 1: Genomics to Molecules",
    "section": "4.4 Further Reading",
    "text": "4.4 Further Reading\n@opentargets @uniprot @chembl @pdb\n\n4.4.1 1. Retrieve ALS Target Genes from Open Targets\nimport requests\nefo_id = \"Orphanet_803\"  # ALS\not_url = f\"https://platform-api.opentargets.io/v3/platform/public/association/filter?disease={efo_id}&size=30&fields=target.gene_info.symbol,target.gene_info.name,association_score.overall\"\nresp = requests.get(ot_url)\ngene_hits = resp.json().get('data', [])\nals_genes = [g['target']['gene_info']['symbol'] for g in gene_hits]\nprint('Top ALS target genes:', als_genes)\n\n\n4.4.2 2. Batch Extract Non-Protein Entities from PDB\nimport requests, pandas as pd\npdb_ids = ['2RSQ', '4RFX', '7WWT', ...]  # your PDB list\nall_results = []\nfor pdb_id in pdb_ids:\n    url = f'https://data.rcsb.org/rest/v1/core/entry/{pdb_id}'\n    resp = requests.get(url)\n    if resp.status_code == 200:\n        data = resp.json()\n        for entity in data.get('nonpolymer_entities', []):\n            chem_comp = entity.get('chem_comp', {})\n            all_results.append({\n                'pdb_id': pdb_id,\n                ---\n\n                ## Interpretation of Exported Ligands for ALS Drug Discovery\n\n                At the end of this workflow, the notebook exports a file `ligands_for_docking.csv` containing known ligands for the selected ALS target (e.g., SOD1). Here is an example of the exported data:\n\n                | name         | smiles                                                        |\n                |--------------|---------------------------------------------------------------|\n                | CHEMBL273030 | c1ccc2cc3c(NCCc4c[nH]cn4)nnc(NCCc4c[nH]cn4)c3cc2c1           |\n                | CHEMBL272808 | Clc1nnc(NCCc2c[nH]cn2)c2cc3ccccc3cc12                        |\n                | CHEMBL272641 | c1ccc2cc3c(NCCCn4ccnc4)nnc(NCCCn4ccnc4)c3cc2c1               |\n                | CHEMBL405899 | Clc1nnc(NCCCn2ccnc2)c2cc3ccccc3cc12                          |\n                | CHEMBL1672028| c1ccc2cc3c(Nc4cc[nH]n4)nnc(Nc4cc[nH]n4)c3cc2c1               |\n\n                **How to interpret these results:**\n\n                - These ligands are ChEMBL compounds with known bioactivity, retrieved for the ALS target SOD1.\n                - Their structures are consistent with CNS drug-like scaffolds, but further ADMET and blood-brain barrier predictions are needed for ALS relevance.\n                - These molecules are not validated ALS drugs, but are reasonable starting points for hit discovery and virtual screening.\n                - The CSV can be used directly in docking or cheminformatics pipelines to prioritize or design new compounds.\n\n                **Limitations:**\n                - The activity data is typically from in vitro assays, not ALS disease models.\n                - Further experimental validation is required to confirm efficacy and safety in ALS.\n\n                **Summary:**\n                The notebook provides a practical, automated way to go from ALS gene to actionable ligand lists for computational drug discovery, enabling rapid hypothesis generation and screening for ALS research.\n                'entity_id': chem_comp.get('id', ''),\n                'entity_name': chem_comp.get('name', ''),\n                'entity_type': chem_comp.get('type', '')\n            })\npd.DataFrame(all_results).to_csv('batch_als_pdb_entities.csv', index=False)\n\n\n4.4.3 3. Find Known Ligands for a Target in ChEMBL\nfrom chembl_webresource_client.new_client import new_client\ntarget = new_client.target\nactivity = new_client.activity\nacc = 'P00441'  # UniProt for SOD1\ntargets = list(target.filter(target_components__accession=acc))\nchembl_id = targets[0]['target_chembl_id']\nacts = activity.filter(target_chembl_id=chembl_id, standard_type='IC50')\nfor a in list(acts)[:5]:\n    print(a.get('molecule_chembl_id'), a.get('standard_value'))",
    "crumbs": [
      "Part 0: Getting Started",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 1: Genomics to Molecules</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1-genomics-to-molecules.html#notebook-link",
    "href": "chapters/chapter1-genomics-to-molecules.html#notebook-link",
    "title": "4  Chapter 1: Genomics to Molecules",
    "section": "4.5 Notebook Link",
    "text": "4.5 Notebook Link\nFor the full workflow, see the interactive notebook: chapter1-genomics-to-molecules.ipynb",
    "crumbs": [
      "Part 0: Getting Started",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 1: Genomics to Molecules</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1-genomics-to-molecules.html#introduction-to-genomics-in-drug-discovery",
    "href": "chapters/chapter1-genomics-to-molecules.html#introduction-to-genomics-in-drug-discovery",
    "title": "4  Chapter 1: Genomics to Molecules",
    "section": "4.6 1.1 Introduction to Genomics in Drug Discovery",
    "text": "4.6 1.1 Introduction to Genomics in Drug Discovery\nGenomics provides the foundation for modern drug discovery by identifying genes associated with diseases. Advances in sequencing technologies and bioinformatics enable researchers to pinpoint genetic variants and pathways involved in disease mechanisms, offering new opportunities for therapeutic intervention.",
    "crumbs": [
      "Part 0: Getting Started",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 1: Genomics to Molecules</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1-genomics-to-molecules.html#from-genes-to-proteins",
    "href": "chapters/chapter1-genomics-to-molecules.html#from-genes-to-proteins",
    "title": "4  Chapter 1: Genomics to Molecules",
    "section": "4.7 1.2 From Genes to Proteins",
    "text": "4.7 1.2 From Genes to Proteins\nGenes encode proteins, which are the functional molecules in cells. Understanding how genetic information is translated into protein structure and function is crucial for identifying druggable targets. Databases like UniProt provide comprehensive information on protein sequences, structures, and functions.",
    "crumbs": [
      "Part 0: Getting Started",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 1: Genomics to Molecules</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1-genomics-to-molecules.html#target-identification-and-validation",
    "href": "chapters/chapter1-genomics-to-molecules.html#target-identification-and-validation",
    "title": "4  Chapter 1: Genomics to Molecules",
    "section": "4.8 1.3 Target Identification and Validation",
    "text": "4.8 1.3 Target Identification and Validation\nTarget identification involves linking disease-associated genes to specific proteins that can be modulated by drugs. Validation ensures that modulating the target will have a therapeutic effect. This process uses data from genomics, proteomics, and functional studies, and often leverages resources like Open Targets and experimental validation.",
    "crumbs": [
      "Part 0: Getting Started",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 1: Genomics to Molecules</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1-genomics-to-molecules.html#linking-targets-to-molecules",
    "href": "chapters/chapter1-genomics-to-molecules.html#linking-targets-to-molecules",
    "title": "4  Chapter 1: Genomics to Molecules",
    "section": "4.9 1.4 Linking Targets to Molecules",
    "text": "4.9 1.4 Linking Targets to Molecules\nOnce a target protein is identified and validated, the next step is to find small molecules that interact with it. This involves searching bioactivity databases (e.g., ChEMBL) for known ligands, using structure-based methods to identify binding sites, and applying cheminformatics tools to analyze and prioritize compounds.",
    "crumbs": [
      "Part 0: Getting Started",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 1: Genomics to Molecules</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1-genomics-to-molecules.html#case-study-als-gene-to-ligand",
    "href": "chapters/chapter1-genomics-to-molecules.html#case-study-als-gene-to-ligand",
    "title": "4  Chapter 1: Genomics to Molecules",
    "section": "4.10 1.5 Case Study: ALS Gene to Ligand",
    "text": "4.10 1.5 Case Study: ALS Gene to Ligand\nAmyotrophic lateral sclerosis (ALS) is a neurodegenerative disease with several known genetic risk factors, such as mutations in the SOD1 gene. In this case study, we: - Identify ALS-associated genes using Open Targets. - Retrieve the corresponding protein (e.g., SOD1) from UniProt. - Find known ligands for SOD1 in ChEMBL. - Analyze ligand properties and prepare them for virtual screening or further optimization.\nThis workflow demonstrates how to bridge genomics and cheminformatics for rational drug discovery, starting from a disease gene and ending with actionable small molecules.",
    "crumbs": [
      "Part 0: Getting Started",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 1: Genomics to Molecules</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1-genomics-to-molecules.html#interpretation-of-exported-ligands-for-als-drug-discovery",
    "href": "chapters/chapter1-genomics-to-molecules.html#interpretation-of-exported-ligands-for-als-drug-discovery",
    "title": "4  Chapter 1: Genomics to Molecules",
    "section": "4.11 Interpretation of Exported Ligands for ALS Drug Discovery",
    "text": "4.11 Interpretation of Exported Ligands for ALS Drug Discovery\nAt the end of this workflow, the notebook exports a file ligands_for_docking.csv containing known ligands for the selected ALS target (e.g., SOD1). Here is an example of the exported data:\n\n\n\n\n\n\n\nname\nsmiles\n\n\n\n\nCHEMBL273030\nc1ccc2cc3c(NCCc4c[nH]cn4)nnc(NCCc4c[nH]cn4)c3cc2c1\n\n\nCHEMBL272808\nClc1nnc(NCCc2c[nH]cn2)c2cc3ccccc3cc12\n\n\nCHEMBL272641\nc1ccc2cc3c(NCCCn4ccnc4)nnc(NCCCn4ccnc4)c3cc2c1\n\n\nCHEMBL405899\nClc1nnc(NCCCn2ccnc2)c2cc3ccccc3cc12\n\n\nCHEMBL1672028\nc1ccc2cc3c(Nc4cc[nH]n4)nnc(Nc4cc[nH]n4)c3cc2c1\n\n\n\nHow to interpret these results:\n\nThese ligands are ChEMBL compounds with known bioactivity, retrieved for the ALS target SOD1.\nTheir structures are consistent with CNS drug-like scaffolds, but further ADMET and blood-brain barrier predictions are needed for ALS relevance.\nThese molecules are not validated ALS drugs, but are reasonable starting points for hit discovery and virtual screening.\nThe CSV can be used directly in docking or cheminformatics pipelines to prioritize or design new compounds.\n\nLimitations: - The activity data is typically from in vitro assays, not ALS disease models. - Further experimental validation is required to confirm efficacy and safety in ALS.\nSummary: The notebook provides a practical, automated way to go from ALS gene to actionable ligand lists for computational drug discovery, enabling rapid hypothesis generation and screening for ALS research.",
    "crumbs": [
      "Part 0: Getting Started",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 1: Genomics to Molecules</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2-environment-setup.html",
    "href": "chapters/chapter2-environment-setup.html",
    "title": "5  Chapter 2: Environment Setup",
    "section": "",
    "text": "5.1 2.1 Installing Python and Conda\nThis chapter guides you through setting up a reproducible computational environment for AI-driven drug discovery, including Python, Jupyter, and essential libraries.\nTo get started, you need Python and a package manager. Conda is recommended for managing environments and dependencies.\nSteps:",
    "crumbs": [
      "Part 0: Getting Started",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 2: Environment Setup</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2-environment-setup.html#installing-python-and-conda",
    "href": "chapters/chapter2-environment-setup.html#installing-python-and-conda",
    "title": "5  Chapter 2: Environment Setup",
    "section": "",
    "text": "Download and Install Miniconda:\n\nGo to Miniconda Downloads and download the installer for your OS.\nRun the installer and follow the prompts.\n\nVerify Installation:\n\nOpen a terminal and run:\nconda --version\nYou should see the conda version printed.\n\nCreate a New Environment:\n\nExample for Python 3.10:\nconda create -n drug-discovery python=3.10\nconda activate drug-discovery",
    "crumbs": [
      "Part 0: Getting Started",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 2: Environment Setup</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2-environment-setup.html#setting-up-jupyter-notebooks",
    "href": "chapters/chapter2-environment-setup.html#setting-up-jupyter-notebooks",
    "title": "5  Chapter 2: Environment Setup",
    "section": "5.2 2.2 Setting Up Jupyter Notebooks",
    "text": "5.2 2.2 Setting Up Jupyter Notebooks\nJupyter Notebooks are essential for interactive coding and documentation.\nSteps:\n\nInstall Jupyter: bash     conda install jupyterlab\nLaunch JupyterLab: bash     jupyter lab\n\nThis will open JupyterLab in your browser.\n\nCreate a New Notebook:\n\nIn JupyterLab, click “Python 3” under the Notebook section to start a new notebook.",
    "crumbs": [
      "Part 0: Getting Started",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 2: Environment Setup</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2-environment-setup.html#managing-dependencies",
    "href": "chapters/chapter2-environment-setup.html#managing-dependencies",
    "title": "5  Chapter 2: Environment Setup",
    "section": "5.3 2.3 Managing Dependencies",
    "text": "5.3 2.3 Managing Dependencies\nManaging dependencies ensures reproducibility and avoids conflicts.\nBest Practices:\n\nUse conda or pip to install packages:\nconda install numpy pandas scikit-learn\npip install rdkit matplotlib\nExport your environment for sharing:\nconda env export &gt; environment.yml\nRecreate an environment from a file:\nconda env create -f environment.yml",
    "crumbs": [
      "Part 0: Getting Started",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 2: Environment Setup</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2-environment-setup.html#version-control-with-git",
    "href": "chapters/chapter2-environment-setup.html#version-control-with-git",
    "title": "5  Chapter 2: Environment Setup",
    "section": "5.4 2.4 Version Control with Git",
    "text": "5.4 2.4 Version Control with Git\nVersion control is critical for tracking changes and collaborating.\nSteps:\n\nInstall Git:\n\nDownload from git-scm.com and follow installation instructions for your OS.\n\nConfigure Git: bash     git config --global user.name \"Your Name\"     git config --global user.email \"you@example.com\"\nInitialize a Repository: bash     git init\nBasic Workflow: bash     git add .     git commit -m \"Initial commit\"     git remote add origin &lt;your-repo-url&gt;     git push -u origin main",
    "crumbs": [
      "Part 0: Getting Started",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 2: Environment Setup</span>"
    ]
  },
  {
    "objectID": "part1-foundations.html",
    "href": "part1-foundations.html",
    "title": "6  Part I: Foundations",
    "section": "",
    "text": "7 Part I: Foundations\nThis part introduces the essential concepts and tools for AI-driven drug discovery, including cheminformatics, molecular representations, and compound screening.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Part I: Foundations</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3-cheminformatics.html",
    "href": "chapters/chapter3-cheminformatics.html",
    "title": "7  Chapter 3: Cheminformatics Essentials",
    "section": "",
    "text": "7.1 3.1 Molecular Representations (SMILES, InChI)\nCheminformatics is the foundation for representing, searching, and analyzing chemical structures computationally. This chapter covers molecular representations, file formats, and basic cheminformatics operations.\nMolecular representations are ways to describe chemical structures in a form that computers can process.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 3: Cheminformatics Essentials</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3-cheminformatics.html#molecular-representations-smiles-inchi",
    "href": "chapters/chapter3-cheminformatics.html#molecular-representations-smiles-inchi",
    "title": "7  Chapter 3: Cheminformatics Essentials",
    "section": "",
    "text": "SMILES (Simplified Molecular Input Line Entry System):\n\nA line notation for describing the structure of chemical species using short ASCII strings.\nExample: Ethanol = CCO, Benzene = c1ccccc1\nWidely used for database storage and cheminformatics tools.\n\nInChI (International Chemical Identifier):\n\nA textual identifier for chemical substances, designed to be unique and non-proprietary.\nExample: Ethanol = InChI=1S/C2H6O/c1-2-3/h3H,2H2,1H3\nUseful for interoperability and linking chemical information across databases.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 3: Cheminformatics Essentials</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3-cheminformatics.html#chemical-file-formats",
    "href": "chapters/chapter3-cheminformatics.html#chemical-file-formats",
    "title": "7  Chapter 3: Cheminformatics Essentials",
    "section": "7.2 3.2 Chemical File Formats",
    "text": "7.2 3.2 Chemical File Formats\nChemical file formats store molecular structures and related data. Common formats include:\n\nSDF (Structure Data File):\n\nStores multiple molecules with associated data fields.\nUsed for compound libraries and virtual screening.\n\nMOL/MOL2:\n\nEncodes 2D/3D structure, atom types, and bond information.\nMOL2 supports more detailed atom typing and charges.\n\nPDB (Protein Data Bank):\n\nUsed for macromolecules (proteins, nucleic acids) and some small molecules.\nContains 3D coordinates and metadata.\n\nCSV/TSV:\n\nTabular formats often used to store SMILES or InChI strings with associated data.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 3: Cheminformatics Essentials</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3-cheminformatics.html#structure-search-and-similarity",
    "href": "chapters/chapter3-cheminformatics.html#structure-search-and-similarity",
    "title": "7  Chapter 3: Cheminformatics Essentials",
    "section": "7.3 3.3 Structure Search and Similarity",
    "text": "7.3 3.3 Structure Search and Similarity\nCheminformatics enables searching for molecules by structure and comparing their similarity.\n\nExact Structure Search:\n\nFinds molecules that are identical to a query structure.\n\nSubstructure Search:\n\nFinds molecules containing a specific substructure (e.g., a benzene ring).\n\nSimilarity Search:\n\nFinds molecules similar to a query, often using fingerprints and Tanimoto similarity.\nExample: RDKit can compute molecular fingerprints and similarity scores.\n\n\nExample (Python/RDKit):\nfrom rdkit import Chem\nfrom rdkit.Chem import DataStructs, AllChem\n\nmol1 = Chem.MolFromSmiles('CCO')\nmol2 = Chem.MolFromSmiles('CCN')\nfp1 = AllChem.GetMorganFingerprintAsBitVect(mol1, 2)\nfp2 = AllChem.GetMorganFingerprintAsBitVect(mol2, 2)\nsimilarity = DataStructs.TanimotoSimilarity(fp1, fp2)\nprint(f\"Tanimoto similarity: {similarity:.2f}\")",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 3: Cheminformatics Essentials</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3-cheminformatics.html#cheminformatics-toolkits",
    "href": "chapters/chapter3-cheminformatics.html#cheminformatics-toolkits",
    "title": "7  Chapter 3: Cheminformatics Essentials",
    "section": "7.4 3.4 Cheminformatics Toolkits",
    "text": "7.4 3.4 Cheminformatics Toolkits\nSeveral open-source toolkits provide cheminformatics functionality:\n\nRDKit:\n\nPython/C++ library for molecular manipulation, descriptor calculation, and visualization.\nRDKit Documentation\n\nOpen Babel:\n\nCommand-line and Python tools for converting between file formats and basic cheminformatics operations.\nOpen Babel\n\nCDK (Chemistry Development Kit):\n\nJava library for cheminformatics, used in many bioinformatics tools.\n\n\nThese toolkits support reading/writing file formats, structure search, descriptor calculation, and more.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 3: Cheminformatics Essentials</span>"
    ]
  },
  {
    "objectID": "chapters/chapter4-molecular-fingerprints.html",
    "href": "chapters/chapter4-molecular-fingerprints.html",
    "title": "8  Chapter 4: Molecular Fingerprints",
    "section": "",
    "text": "8.1 4.1 What Are Molecular Fingerprints?\nMolecular fingerprints are compact representations of chemical structures used for similarity searching and machine learning. This chapter explains different types of fingerprints and their applications.\nMolecular fingerprints are binary or integer vectors that encode the presence or absence of particular substructures or features in a molecule. They allow rapid comparison of molecules for similarity searching, clustering, and as input features for machine learning models.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Chapter 4: Molecular Fingerprints</span>"
    ]
  },
  {
    "objectID": "chapters/chapter4-molecular-fingerprints.html#what-are-molecular-fingerprints",
    "href": "chapters/chapter4-molecular-fingerprints.html#what-are-molecular-fingerprints",
    "title": "8  Chapter 4: Molecular Fingerprints",
    "section": "",
    "text": "Purpose:\n\nEnable fast similarity searches in large chemical databases.\nProvide a standardized input for cheminformatics and AI tasks.\n\nHow They Work:\n\nEach bit or value in the fingerprint corresponds to a specific structural feature or pattern.\nThe fingerprint is generated by analyzing the molecule’s structure and mapping features to bits.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Chapter 4: Molecular Fingerprints</span>"
    ]
  },
  {
    "objectID": "chapters/chapter4-molecular-fingerprints.html#types-maccs-morgan-topological",
    "href": "chapters/chapter4-molecular-fingerprints.html#types-maccs-morgan-topological",
    "title": "8  Chapter 4: Molecular Fingerprints",
    "section": "8.2 4.2 Types: MACCS, Morgan, Topological",
    "text": "8.2 4.2 Types: MACCS, Morgan, Topological\nThere are several types of molecular fingerprints, each with different algorithms and applications:\n\nMACCS Keys:\n\n166-bit fingerprint where each bit represents a predefined substructure (e.g., aromatic ring, carboxyl group).\nSimple and interpretable, commonly used for basic similarity searches.\n\nMorgan (Circular) Fingerprints:\n\nAlso known as ECFP (Extended-Connectivity Fingerprints).\nEncodes atom environments up to a certain radius (e.g., ECFP4 uses radius 2).\nWidely used in machine learning and virtual screening.\nExample (Python/RDKit): python       from rdkit import Chem       from rdkit.Chem import AllChem       mol = Chem.MolFromSmiles('CCO')       fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024)       print(list(fp))\n\nTopological (Path-Based) Fingerprints:\n\nEncodes the presence of linear paths of atoms (e.g., Daylight fingerprints).\nGood for capturing connectivity and substructure patterns.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Chapter 4: Molecular Fingerprints</span>"
    ]
  },
  {
    "objectID": "chapters/chapter4-molecular-fingerprints.html#applications-in-virtual-screening",
    "href": "chapters/chapter4-molecular-fingerprints.html#applications-in-virtual-screening",
    "title": "8  Chapter 4: Molecular Fingerprints",
    "section": "8.3 4.3 Applications in Virtual Screening",
    "text": "8.3 4.3 Applications in Virtual Screening\nFingerprints are essential for virtual screening, where large libraries of compounds are searched for molecules similar to a known active compound.\n\nSimilarity Searching:\n\nCompare fingerprints using metrics like Tanimoto similarity to find similar molecules.\n\nSubstructure Searching:\n\nIdentify compounds containing specific structural motifs.\n\nLibrary Design:\n\nCluster compounds based on fingerprint similarity to ensure chemical diversity.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Chapter 4: Molecular Fingerprints</span>"
    ]
  },
  {
    "objectID": "chapters/chapter4-molecular-fingerprints.html#fingerprints-in-machine-learning",
    "href": "chapters/chapter4-molecular-fingerprints.html#fingerprints-in-machine-learning",
    "title": "8  Chapter 4: Molecular Fingerprints",
    "section": "8.4 4.4 Fingerprints in Machine Learning",
    "text": "8.4 4.4 Fingerprints in Machine Learning\nFingerprints are widely used as input features for machine learning models in cheminformatics.\n\nFeature Vectors:\n\nEach molecule is represented by its fingerprint vector, which can be used as input to algorithms like random forests, SVMs, or neural networks.\n\nQSAR Modeling:\n\nQuantitative Structure-Activity Relationship (QSAR) models use fingerprints to predict biological activity or properties.\n\nDeep Learning:\n\nFingerprints can be combined with other descriptors or used as input to deep learning models for property prediction, classification, or regression tasks.\n\n\nExample (Python/Scikit-learn):\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\nfrom sklearn.ensemble import RandomForestClassifier\nimport numpy as np\n\n# Example molecules and labels\nsmiles = ['CCO', 'CCN', 'CCC', 'CCCl']\nlabels = [1, 0, 1, 0]\nfps = [AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(s), 2, nBits=1024) for s in smiles]\nX = np.array([list(fp) for fp in fps])\n\nclf = RandomForestClassifier()\nclf.fit(X, labels)",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Chapter 4: Molecular Fingerprints</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5-molecular-properties.html",
    "href": "chapters/chapter5-molecular-properties.html",
    "title": "9  Chapter 5: Molecular Properties",
    "section": "",
    "text": "9.1 5.1 Physicochemical Descriptors\nThis chapter explores key physicochemical properties of molecules (e.g., logP, MW, H-bond donors/acceptors) and their importance in drug design and ADMET prediction.\nPhysicochemical descriptors are numerical values that capture important chemical and physical properties of molecules. These descriptors are crucial for understanding drug-likeness, solubility, permeability, and ADMET (Absorption, Distribution, Metabolism, Excretion, Toxicity) properties.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chapter 5: Molecular Properties</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5-molecular-properties.html#physicochemical-descriptors",
    "href": "chapters/chapter5-molecular-properties.html#physicochemical-descriptors",
    "title": "9  Chapter 5: Molecular Properties",
    "section": "",
    "text": "Common Descriptors:\n\nMolecular Weight (MW): Total mass of a molecule.\nLogP: Partition coefficient between octanol and water, indicating hydrophobicity.\nHydrogen Bond Donors (HBD): Number of hydrogen atoms attached to electronegative atoms (e.g., N-H, O-H).\nHydrogen Bond Acceptors (HBA): Number of electronegative atoms with lone pairs (e.g., N, O).\nTopological Polar Surface Area (TPSA): Surface area contributed by polar atoms, related to absorption and permeability.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chapter 5: Molecular Properties</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5-molecular-properties.html#calculating-properties-with-rdkit",
    "href": "chapters/chapter5-molecular-properties.html#calculating-properties-with-rdkit",
    "title": "9  Chapter 5: Molecular Properties",
    "section": "9.2 5.2 Calculating Properties with RDKit",
    "text": "9.2 5.2 Calculating Properties with RDKit\nRDKit is a popular cheminformatics toolkit for calculating molecular properties in Python.\nExample (Python/RDKit):\nfrom rdkit import Chem\nfrom rdkit.Chem import Descriptors\n\nsmiles = 'CCO'  # Ethanol\nmol = Chem.MolFromSmiles(smiles)\nmw = Descriptors.MolWt(mol)\nlogp = Descriptors.MolLogP(mol)\nhbd = Descriptors.NumHDonors(mol)\nhba = Descriptors.NumHAcceptors(mol)\ntpsa = Descriptors.TPSA(mol)\n\nprint(f\"MW: {mw:.2f}, LogP: {logp:.2f}, HBD: {hbd}, HBA: {hba}, TPSA: {tpsa:.2f}\")",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chapter 5: Molecular Properties</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5-molecular-properties.html#lipinskis-rule-of-five",
    "href": "chapters/chapter5-molecular-properties.html#lipinskis-rule-of-five",
    "title": "9  Chapter 5: Molecular Properties",
    "section": "9.3 5.3 Lipinski’s Rule of Five",
    "text": "9.3 5.3 Lipinski’s Rule of Five\nLipinski’s Rule of Five is a set of guidelines to evaluate drug-likeness and oral bioavailability:\n\nRules:\n\nMW ≤ 500 Da\nLogP ≤ 5\nHBD ≤ 5\nHBA ≤ 10\n\n\nCompounds that violate more than one rule are less likely to be orally active drugs.\nApplication: Use these rules to filter compound libraries for drug discovery projects.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chapter 5: Molecular Properties</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5-molecular-properties.html#property-based-filtering",
    "href": "chapters/chapter5-molecular-properties.html#property-based-filtering",
    "title": "9  Chapter 5: Molecular Properties",
    "section": "9.4 5.4 Property-Based Filtering",
    "text": "9.4 5.4 Property-Based Filtering\nProperty-based filtering is used to select compounds with desirable physicochemical properties for further study.\n\nFiltering Strategies:\n\nRemove compounds with poor solubility or permeability.\nApply Lipinski’s rules and other property thresholds (e.g., TPSA, rotatable bonds).\n\nExample (Python/RDKit):\n\nfrom rdkit import Chem\nfrom rdkit.Chem import Descriptors\n\ndef passes_lipinski(mol):\n        mw = Descriptors.MolWt(mol)\n        logp = Descriptors.MolLogP(mol)\n        hbd = Descriptors.NumHDonors(mol)\n        hba = Descriptors.NumHAcceptors(mol)\n        return (mw &lt;= 500 and logp &lt;= 5 and hbd &lt;= 5 and hba &lt;= 10)\n\nsmiles_list = ['CCO', 'CCN(CC)CC', 'CCCCCCCCCCCCCCCC(=O)O']\nfor smi in smiles_list:\n        mol = Chem.MolFromSmiles(smi)\n        if passes_lipinski(mol):\n                print(f\"{smi} passes Lipinski's rules\")\n        else:\n                print(f\"{smi} fails Lipinski's rules\")",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chapter 5: Molecular Properties</span>"
    ]
  },
  {
    "objectID": "chapters/chapter6-graph-neural-networks.html",
    "href": "chapters/chapter6-graph-neural-networks.html",
    "title": "10  Chapter 6: Graph Neural Networks",
    "section": "",
    "text": "10.1 Summary\nGraph Neural Networks (GNNs) are powerful tools for learning on molecular graphs. This chapter introduces GNN concepts and their application to molecular property prediction, including how molecules are represented as graphs and how GNNs can learn from these structures.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 6: Graph Neural Networks</span>"
    ]
  },
  {
    "objectID": "chapters/chapter6-graph-neural-networks.html#key-code-snippets",
    "href": "chapters/chapter6-graph-neural-networks.html#key-code-snippets",
    "title": "10  Chapter 6: Graph Neural Networks",
    "section": "10.2 Key Code Snippets",
    "text": "10.2 Key Code Snippets\n\n10.2.1 1. Construct a Molecular Graph with RDKit and NetworkX\nfrom rdkit import Chem\nimport networkx as nx\nsmiles = \"CCO\"\nmol = Chem.MolFromSmiles(smiles)\nG = nx.Graph()\nfor atom in mol.GetAtoms():\n    G.add_node(atom.GetIdx(), label=atom.GetSymbol())\nfor bond in mol.GetBonds():\n    G.add_edge(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx(), type=bond.GetBondType())\n\n\n10.2.2 2. Simple GNN Layer with PyTorch Geometric\nfrom torch_geometric.nn import GCNConv\nimport torch\nconv = GCNConv(in_channels=10, out_channels=16)\nx = torch.randn((num_nodes, 10))\nedge_index = ...  # edge list as tensor\nout = conv(x, edge_index)",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 6: Graph Neural Networks</span>"
    ]
  },
  {
    "objectID": "chapters/chapter6-graph-neural-networks.html#notebook-link",
    "href": "chapters/chapter6-graph-neural-networks.html#notebook-link",
    "title": "10  Chapter 6: Graph Neural Networks",
    "section": "10.3 Notebook Link",
    "text": "10.3 Notebook Link\nFor a full workflow, see the interactive notebook: (notebook not available for this chapter)",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 6: Graph Neural Networks</span>"
    ]
  },
  {
    "objectID": "chapters/chapter6-graph-neural-networks.html#introduction-to-gnns",
    "href": "chapters/chapter6-graph-neural-networks.html#introduction-to-gnns",
    "title": "10  Chapter 6: Graph Neural Networks",
    "section": "10.4 6.1 Introduction to GNNs",
    "text": "10.4 6.1 Introduction to GNNs\nGraph Neural Networks (GNNs) are a class of deep learning models designed to operate on graph-structured data. In chemistry, molecules are naturally represented as graphs, with atoms as nodes and bonds as edges. GNNs can learn to predict molecular properties by aggregating information from neighboring atoms and bonds, capturing both local and global structure.\nKey Concepts: - Message passing: Nodes exchange information with neighbors to update their representations. - Permutation invariance: GNNs produce the same output regardless of node ordering. - Applications: Property prediction, molecular generation, reaction prediction.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 6: Graph Neural Networks</span>"
    ]
  },
  {
    "objectID": "chapters/chapter6-graph-neural-networks.html#molecular-graph-construction",
    "href": "chapters/chapter6-graph-neural-networks.html#molecular-graph-construction",
    "title": "10  Chapter 6: Graph Neural Networks",
    "section": "10.5 6.2 Molecular Graph Construction",
    "text": "10.5 6.2 Molecular Graph Construction\nTo use GNNs, molecules must be converted into graph representations. Each atom becomes a node, and each bond becomes an edge. Node and edge features can include atom types, hybridization, bond order, and more.\nExample (Python/RDKit + NetworkX):\nfrom rdkit import Chem\nimport networkx as nx\nsmiles = \"CCO\"\nmol = Chem.MolFromSmiles(smiles)\nG = nx.Graph()\nfor atom in mol.GetAtoms():\n    G.add_node(atom.GetIdx(), label=atom.GetSymbol())\nfor bond in mol.GetBonds():\n    G.add_edge(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx(), type=bond.GetBondType())",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 6: Graph Neural Networks</span>"
    ]
  },
  {
    "objectID": "chapters/chapter6-graph-neural-networks.html#gnn-architectures-for-chemistry",
    "href": "chapters/chapter6-graph-neural-networks.html#gnn-architectures-for-chemistry",
    "title": "10  Chapter 6: Graph Neural Networks",
    "section": "10.6 6.3 GNN Architectures for Chemistry",
    "text": "10.6 6.3 GNN Architectures for Chemistry\nSeveral GNN architectures are used in molecular modeling: - Graph Convolutional Networks (GCN): Aggregate features from neighbors using weighted sums. - Message Passing Neural Networks (MPNN): General framework for message passing and update functions. - Graph Attention Networks (GAT): Use attention mechanisms to weigh neighbor contributions. - Graph Isomorphism Networks (GIN): Designed for maximum discriminative power.\nPopular Libraries: PyTorch Geometric, DGL, DeepChem.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 6: Graph Neural Networks</span>"
    ]
  },
  {
    "objectID": "chapters/chapter6-graph-neural-networks.html#case-study-gnn-for-solubility",
    "href": "chapters/chapter6-graph-neural-networks.html#case-study-gnn-for-solubility",
    "title": "10  Chapter 6: Graph Neural Networks",
    "section": "10.7 6.4 Case Study: GNN for Solubility",
    "text": "10.7 6.4 Case Study: GNN for Solubility\nIn this case study, a GNN is trained to predict aqueous solubility (logS) of small molecules.\nWorkflow: 1. Prepare a dataset of molecules with known solubility values (e.g., ESOL dataset). 2. Convert SMILES to molecular graphs with atom and bond features. 3. Train a GNN (e.g., MPNN or GCN) to predict logS from graph representations. 4. Evaluate model performance using RMSE or R2 metrics.\nExample (Conceptual):\n# Pseudocode for GNN solubility prediction\nfrom torch_geometric.nn import GCNConv\nimport torch\nclass GNN(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = GCNConv(in_channels, hidden)\n        self.conv2 = GCNConv(hidden, 1)\n    def forward(self, x, edge_index):\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index)\n        return x\n# Train on molecular graphs and solubility labels",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 6: Graph Neural Networks</span>"
    ]
  },
  {
    "objectID": "chapters/chapter7-bioactivity-prediction.html",
    "href": "chapters/chapter7-bioactivity-prediction.html",
    "title": "11  Chapter 7: Bioactivity Prediction",
    "section": "",
    "text": "11.1 Summary\nPredicting the biological activity of molecules is central to drug discovery. This chapter covers data sources, machine learning models, and evaluation strategies for bioactivity prediction, including how to prepare data and assess model performance.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Chapter 7: Bioactivity Prediction</span>"
    ]
  },
  {
    "objectID": "chapters/chapter7-bioactivity-prediction.html#key-code-snippets",
    "href": "chapters/chapter7-bioactivity-prediction.html#key-code-snippets",
    "title": "11  Chapter 7: Bioactivity Prediction",
    "section": "11.2 Key Code Snippets",
    "text": "11.2 Key Code Snippets\n\n11.2.1 1. Load Bioactivity Data from ChEMBL\nfrom chembl_webresource_client.new_client import new_client\nactivity = new_client.activity\nacts = activity.filter(target_chembl_id=\"CHEMBL25\", standard_type=\"IC50\")\nfor a in list(acts)[:5]:\n    print(a['molecule_chembl_id'], a['standard_value'])\n\n\n11.2.2 2. Train a Classifier for Bioactivity\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nX = ...  # feature matrix\ny = ...  # binary activity labels\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)\nprint(\"Accuracy:\", clf.score(X_test, y_test))",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Chapter 7: Bioactivity Prediction</span>"
    ]
  },
  {
    "objectID": "chapters/chapter7-bioactivity-prediction.html#notebook-link",
    "href": "chapters/chapter7-bioactivity-prediction.html#notebook-link",
    "title": "11  Chapter 7: Bioactivity Prediction",
    "section": "11.3 Notebook Link",
    "text": "11.3 Notebook Link\nFor a full workflow, see the interactive notebook: (notebook not available for this chapter)",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Chapter 7: Bioactivity Prediction</span>"
    ]
  },
  {
    "objectID": "chapters/chapter7-bioactivity-prediction.html#bioactivity-data-sources",
    "href": "chapters/chapter7-bioactivity-prediction.html#bioactivity-data-sources",
    "title": "11  Chapter 7: Bioactivity Prediction",
    "section": "11.4 7.1 Bioactivity Data Sources",
    "text": "11.4 7.1 Bioactivity Data Sources\nBioactivity data links chemical structures to their effects on biological targets. Key public sources include: - ChEMBL: Large database of bioactive molecules with activity data (IC50, Ki, etc.) and assay details. - PubChem BioAssay: Repository of biological assay results for small molecules. - BindingDB: Focuses on binding affinities for protein-ligand complexes. - Other sources: In-house screening data, literature mining, and collaborative consortia.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Chapter 7: Bioactivity Prediction</span>"
    ]
  },
  {
    "objectID": "chapters/chapter7-bioactivity-prediction.html#feature-engineering-for-bioactivity",
    "href": "chapters/chapter7-bioactivity-prediction.html#feature-engineering-for-bioactivity",
    "title": "11  Chapter 7: Bioactivity Prediction",
    "section": "11.5 7.2 Feature Engineering for Bioactivity",
    "text": "11.5 7.2 Feature Engineering for Bioactivity\nFeature engineering transforms raw molecular data into numerical representations suitable for machine learning. - Molecular fingerprints: ECFP (Morgan), MACCS, topological fingerprints. - Descriptors: Physicochemical properties (e.g., MW, logP, H-bond donors/acceptors, TPSA). - Target features: Protein sequence descriptors, structural features, or target class labels. - Data preprocessing: Standardize SMILES, remove duplicates, handle missing values, and balance classes.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Chapter 7: Bioactivity Prediction</span>"
    ]
  },
  {
    "objectID": "chapters/chapter7-bioactivity-prediction.html#ml-models-for-activity-prediction",
    "href": "chapters/chapter7-bioactivity-prediction.html#ml-models-for-activity-prediction",
    "title": "11  Chapter 7: Bioactivity Prediction",
    "section": "11.6 7.3 ML Models for Activity Prediction",
    "text": "11.6 7.3 ML Models for Activity Prediction\nVarious machine learning models are used to predict bioactivity: - Random Forests: Robust to noisy data, handle high-dimensional features well. - Support Vector Machines (SVM): Effective for binary classification with clear margins. - Neural Networks: Capture complex, non-linear relationships; can be used for regression or classification. - Deep Learning: Graph neural networks (GNNs), convolutional networks for molecular graphs or SMILES. - Model selection: Depends on data size, feature type, and interpretability needs.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Chapter 7: Bioactivity Prediction</span>"
    ]
  },
  {
    "objectID": "chapters/chapter7-bioactivity-prediction.html#model-evaluation-and-validation",
    "href": "chapters/chapter7-bioactivity-prediction.html#model-evaluation-and-validation",
    "title": "11  Chapter 7: Bioactivity Prediction",
    "section": "11.7 7.4 Model Evaluation and Validation",
    "text": "11.7 7.4 Model Evaluation and Validation\nEvaluating model performance is critical for reliable predictions. - Metrics: Accuracy, ROC-AUC, precision, recall, F1-score for classification; RMSE, R2 for regression. - Cross-validation: Use k-fold or stratified cross-validation to assess generalizability. - External validation: Test on independent datasets or prospective experiments. - Interpretability: Analyze feature importance, SHAP values, or model explanations to understand predictions.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Chapter 7: Bioactivity Prediction</span>"
    ]
  },
  {
    "objectID": "chapters/chapter8-admet-prediction.html",
    "href": "chapters/chapter8-admet-prediction.html",
    "title": "12  Chapter 8: ADMET Prediction",
    "section": "",
    "text": "12.1 Summary\nADMET (Absorption, Distribution, Metabolism, Excretion, Toxicity) properties are critical for drug candidates. This chapter discusses computational approaches for ADMET prediction, including data sources, descriptors, and machine learning models.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 8: ADMET Prediction</span>"
    ]
  },
  {
    "objectID": "chapters/chapter8-admet-prediction.html#key-code-snippets",
    "href": "chapters/chapter8-admet-prediction.html#key-code-snippets",
    "title": "12  Chapter 8: ADMET Prediction",
    "section": "12.2 Key Code Snippets",
    "text": "12.2 Key Code Snippets\n\n12.2.1 1. Calculate ADMET Descriptors with RDKit\nfrom rdkit import Chem\nfrom rdkit.Chem import Crippen, Descriptors\nsmiles = \"CCO\"\nmol = Chem.MolFromSmiles(smiles)\nlogp = Crippen.MolLogP(mol)\nmw = Descriptors.MolWt(mol)\nprint(f\"LogP: {logp}, MW: {mw}\")\n\n\n12.2.2 2. Predict Toxicity with a Pretrained Model (Example)\n# Example only: replace with actual model\nimport joblib\nmodel = joblib.load('tox_model.pkl')\nX = ...  # feature matrix\ntox_pred = model.predict(X)",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 8: ADMET Prediction</span>"
    ]
  },
  {
    "objectID": "chapters/chapter8-admet-prediction.html#notebook-link",
    "href": "chapters/chapter8-admet-prediction.html#notebook-link",
    "title": "12  Chapter 8: ADMET Prediction",
    "section": "12.3 Notebook Link",
    "text": "12.3 Notebook Link\nFor a full workflow, see the interactive notebook: (notebook not available for this chapter)",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 8: ADMET Prediction</span>"
    ]
  },
  {
    "objectID": "chapters/chapter8-admet-prediction.html#introduction-to-admet",
    "href": "chapters/chapter8-admet-prediction.html#introduction-to-admet",
    "title": "12  Chapter 8: ADMET Prediction",
    "section": "12.4 8.1 Introduction to ADMET",
    "text": "12.4 8.1 Introduction to ADMET\nADMET stands for Absorption, Distribution, Metabolism, Excretion, and Toxicity. These properties determine whether a compound is likely to become a safe and effective drug. Poor ADMET characteristics are a major cause of drug candidate failure in clinical trials.\n\nAbsorption: How well a drug is taken up into the bloodstream.\nDistribution: How the drug spreads through the body and tissues.\nMetabolism: How the drug is broken down, often by liver enzymes.\nExcretion: How the drug and its metabolites are eliminated.\nToxicity: Potential for harmful effects.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 8: ADMET Prediction</span>"
    ]
  },
  {
    "objectID": "chapters/chapter8-admet-prediction.html#data-and-descriptors",
    "href": "chapters/chapter8-admet-prediction.html#data-and-descriptors",
    "title": "12  Chapter 8: ADMET Prediction",
    "section": "12.5 8.2 Data and Descriptors",
    "text": "12.5 8.2 Data and Descriptors\nADMET prediction relies on curated datasets and molecular descriptors that capture relevant chemical and biological properties. - Data sources: - Public databases: ADMETlab, Tox21, ChEMBL, PubChem. - In-house experimental data. - Descriptors: - Physicochemical: MW, logP, TPSA, H-bond donors/acceptors. - Structural: molecular fingerprints, substructure counts. - Biological: predicted or measured interactions with enzymes (e.g., CYP450). - Data curation: - Standardize SMILES, remove duplicates, handle missing values, and balance classes.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 8: ADMET Prediction</span>"
    ]
  },
  {
    "objectID": "chapters/chapter8-admet-prediction.html#ml-models-for-admet",
    "href": "chapters/chapter8-admet-prediction.html#ml-models-for-admet",
    "title": "12  Chapter 8: ADMET Prediction",
    "section": "12.6 8.3 ML Models for ADMET",
    "text": "12.6 8.3 ML Models for ADMET\nMachine learning models are widely used for ADMET property prediction. - Classification models: Predict binary outcomes (e.g., toxic vs. non-toxic, BBB permeable vs. not). - Regression models: Predict continuous values (e.g., logD, clearance rate). - Popular algorithms: Random forests, support vector machines, neural networks, deep learning (e.g., graph neural networks). - Model selection: Depends on property, data size, and interpretability needs. - Multi-task learning: Some models predict multiple ADMET endpoints simultaneously.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 8: ADMET Prediction</span>"
    ]
  },
  {
    "objectID": "chapters/chapter8-admet-prediction.html#interpreting-admet-predictions",
    "href": "chapters/chapter8-admet-prediction.html#interpreting-admet-predictions",
    "title": "12  Chapter 8: ADMET Prediction",
    "section": "12.7 8.4 Interpreting ADMET Predictions",
    "text": "12.7 8.4 Interpreting ADMET Predictions\nInterpreting model predictions is crucial for decision-making in drug discovery. - Performance metrics: Accuracy, ROC-AUC, precision, recall, RMSE, etc. - Feature importance: Identify which descriptors most influence predictions (e.g., SHAP values, permutation importance). - Applicability domain: Assess whether a compound is within the model’s reliable prediction space. - Experimental validation: Always confirm computational predictions with laboratory assays when possible.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 8: ADMET Prediction</span>"
    ]
  },
  {
    "objectID": "chapters/chapter9-molecular-generation.html",
    "href": "chapters/chapter9-molecular-generation.html",
    "title": "13  Chapter 9: Molecular Generation",
    "section": "",
    "text": "13.1 Summary\nGenerative models can design novel molecules with desired properties. This chapter introduces molecular generation techniques, including SMILES-based and graph-based approaches, and discusses how to evaluate generated molecules.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Chapter 9: Molecular Generation</span>"
    ]
  },
  {
    "objectID": "chapters/chapter9-molecular-generation.html#key-code-snippets",
    "href": "chapters/chapter9-molecular-generation.html#key-code-snippets",
    "title": "13  Chapter 9: Molecular Generation",
    "section": "13.2 Key Code Snippets",
    "text": "13.2 Key Code Snippets\n\n13.2.1 1. Generate Molecules with a SMILES RNN (Example)\n# Example only: replace with actual model\nimport torch\nmodel = ...  # pretrained RNN\nz = torch.randn(1, latent_dim)\nsmiles = model.sample(z)\nprint(smiles)\n\n\n13.2.2 2. Evaluate Validity of Generated SMILES\nfrom rdkit import Chem\nsmiles_list = [\"CCO\", \"invalid_smiles\"]\nfor s in smiles_list:\n    mol = Chem.MolFromSmiles(s)\n    print(f\"{s}: {'valid' if mol else 'invalid'}\")",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Chapter 9: Molecular Generation</span>"
    ]
  },
  {
    "objectID": "chapters/chapter9-molecular-generation.html#notebook-link",
    "href": "chapters/chapter9-molecular-generation.html#notebook-link",
    "title": "13  Chapter 9: Molecular Generation",
    "section": "13.3 Notebook Link",
    "text": "13.3 Notebook Link\nFor a full workflow, see the interactive notebook: (notebook not available for this chapter)",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Chapter 9: Molecular Generation</span>"
    ]
  },
  {
    "objectID": "chapters/chapter9-molecular-generation.html#generative-models-overview",
    "href": "chapters/chapter9-molecular-generation.html#generative-models-overview",
    "title": "13  Chapter 9: Molecular Generation",
    "section": "13.4 9.1 Generative Models Overview",
    "text": "13.4 9.1 Generative Models Overview\nGenerative models are machine learning models that can create new data samples similar to those in the training set. In drug discovery, they are used to design novel molecules with desired properties. - Types: - Variational Autoencoders (VAEs) - Generative Adversarial Networks (GANs) - Recurrent Neural Networks (RNNs) - Diffusion models - Applications: - De novo drug design - Scaffold hopping - Library expansion",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Chapter 9: Molecular Generation</span>"
    ]
  },
  {
    "objectID": "chapters/chapter9-molecular-generation.html#smiles-based-generation",
    "href": "chapters/chapter9-molecular-generation.html#smiles-based-generation",
    "title": "13  Chapter 9: Molecular Generation",
    "section": "13.5 9.2 SMILES-Based Generation",
    "text": "13.5 9.2 SMILES-Based Generation\nSMILES-based generative models treat molecules as sequences of characters (SMILES strings). - Approaches: - RNNs, LSTMs, and Transformers trained to generate valid SMILES. - VAEs and GANs adapted for sequence data. - Advantages: - Leverage large SMILES datasets. - Simple to implement and evaluate. - Limitations: - May generate invalid or syntactically incorrect SMILES. - Hard to enforce chemical constraints.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Chapter 9: Molecular Generation</span>"
    ]
  },
  {
    "objectID": "chapters/chapter9-molecular-generation.html#graph-based-generation",
    "href": "chapters/chapter9-molecular-generation.html#graph-based-generation",
    "title": "13  Chapter 9: Molecular Generation",
    "section": "13.6 9.3 Graph-Based Generation",
    "text": "13.6 9.3 Graph-Based Generation\nGraph-based models generate molecules as graphs, with atoms as nodes and bonds as edges. - Approaches: - Graph VAEs, Graph GANs, autoregressive graph models. - Directly model chemical structure and constraints. - Advantages: - Better chemical validity and diversity. - Can encode domain knowledge (e.g., valence rules). - Limitations: - More complex architectures and training.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Chapter 9: Molecular Generation</span>"
    ]
  },
  {
    "objectID": "chapters/chapter9-molecular-generation.html#evaluating-generated-molecules",
    "href": "chapters/chapter9-molecular-generation.html#evaluating-generated-molecules",
    "title": "13  Chapter 9: Molecular Generation",
    "section": "13.7 9.4 Evaluating Generated Molecules",
    "text": "13.7 9.4 Evaluating Generated Molecules\nEvaluating generative models requires assessing both the quality and utility of generated molecules. - Metrics: - Validity: Fraction of chemically valid molecules. - Uniqueness: Fraction of unique molecules generated. - Novelty: Fraction not present in the training set. - Property distribution: Compare properties (e.g., MW, logP) to real molecules. - Practical evaluation: - Visual inspection, property prediction, and virtual screening of generated compounds.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Chapter 9: Molecular Generation</span>"
    ]
  },
  {
    "objectID": "chapters/chapter10-conditional-generation.html",
    "href": "chapters/chapter10-conditional-generation.html",
    "title": "14  Conditional Generation",
    "section": "",
    "text": "15 Chapter 10: Conditional Generation\nConditional generation enables the design of molecules with specific properties or activities. This chapter covers conditional VAEs, GANs, and reinforcement learning for molecular design.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Conditional Generation</span>"
    ]
  },
  {
    "objectID": "chapters/chapter10-conditional-generation.html#conditional-generative-models",
    "href": "chapters/chapter10-conditional-generation.html#conditional-generative-models",
    "title": "14  Conditional Generation",
    "section": "15.1 10.1 Conditional Generative Models",
    "text": "15.1 10.1 Conditional Generative Models\nConditional generative models are deep learning architectures that generate new molecules based on input conditions, such as desired properties or biological activities.\n- Extend standard VAEs by incorporating property or activity information into both the encoder and decoder.\n- Enable sampling of molecules with specific characteristics by conditioning on property vectors.\n- Example: Generating molecules with a target logP or activity value.\n\n- GANs with both generator and discriminator conditioned on property information.\n- Used to generate molecules that satisfy certain constraints or exhibit desired features.\nKey Idea: By conditioning the generative process, these models can be steered toward producing molecules with user-specified attributes.\n\n\n\n\n\ngraph LR\n    A[Input: Molecular Dataset + Property Labels] --&gt; B[Train Conditional Generative Model (cVAE / cGAN)]\n    B --&gt; C[Sample Latent Space &lt;br/&gt; with Property Condition]\n    C --&gt; D[Generate Candidate Molecules]\n    D --&gt; E[Predict / Evaluate Properties]\n    E --&gt;|Iterate / Refine| C\n\n\n\n\n\n\nExample: Conditional VAE in PyTorch (Conceptual)\n# Assume X: molecular features, y: property labels\nclass ConditionalVAE(nn.Module):\n    def __init__(self, ...):\n        # ...\n    def encode(self, x, y):\n        # Concatenate x and y, then encode\n    def decode(self, z, y):\n        # Concatenate z and y, then decode\n    def forward(self, x, y):\n        # ...\n# Training: model(X, y)\n# Generation: sample z, specify y_target, model.decode(z, y_target)\nFurther Reading: @cvae_arxiv @cgan_arxiv",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Conditional Generation</span>"
    ]
  },
  {
    "objectID": "chapters/chapter10-conditional-generation.html#property-conditioned-generation",
    "href": "chapters/chapter10-conditional-generation.html#property-conditioned-generation",
    "title": "14  Conditional Generation",
    "section": "15.2 10.2 Property-Conditioned Generation",
    "text": "15.2 10.2 Property-Conditioned Generation\nProperty-conditioned generation refers to the process of designing molecules that meet specific property requirements (e.g., solubility, bioactivity, toxicity).\n- Concatenate property vectors with molecular representations during training and generation.\n- Use property predictors as part of the loss function to guide the model toward desired outputs.\n\n- Drug design: Generate compounds with high predicted activity and low toxicity.\n- Material science: Design molecules with specific physical or chemical properties.\nExample (Conceptual): 1. Train a cVAE on a dataset of molecules and their properties. 2. At generation time, specify a target property value (e.g., logP = 2.5). 3. Sample from the latent space conditioned on this value to generate new molecules.\nExample: Property-Conditioned SMILES Generation\n# Pseudocode for property-conditioned generation\nproperty_vector = torch.tensor([target_logP, target_activity])\nz = torch.randn(latent_dim)\ngenerated_smiles = model.decode(z, property_vector)\nWorkflow Diagram:\n\n\n\n\n\ngraph LR\n    A[Train Model] --&gt; B[Specify Target Property]\n    B --&gt; C[Sample Latent Vector]\n    C --&gt; D[Generate New SMILES]\n    D --&gt; E[Evaluate Properties]\n    E --&gt;|Refine| B\n\n\n\n\n\n\nFurther Reading: @molgan_arxiv @property_conditioned_review",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Conditional Generation</span>"
    ]
  },
  {
    "objectID": "chapters/chapter10-conditional-generation.html#reinforcement-learning-approaches",
    "href": "chapters/chapter10-conditional-generation.html#reinforcement-learning-approaches",
    "title": "14  Conditional Generation",
    "section": "15.3 10.3 Reinforcement Learning Approaches",
    "text": "15.3 10.3 Reinforcement Learning Approaches\nReinforcement learning (RL) can be used to optimize molecular generation toward specific objectives by treating molecule design as a sequential decision process.\n- The model (agent) generates molecules step by step (e.g., adding atoms/bonds or SMILES tokens).\n- Rewards are given based on how well the generated molecule meets the target property or activity.\n\n- Can include predicted activity, synthetic accessibility, drug-likeness, or other custom criteria.\n\n- REINVENT (policy gradient for SMILES generation)\n- Graph-based RL for molecular graphs\nExample (Conceptual): 1. Define a reward function based on the desired property (e.g., high binding affinity). 2. Use RL to train a generative model to maximize the expected reward. 3. Sample new molecules that are likely to satisfy the design objectives.\nExample: Reinforcement Learning for SMILES Generation\n# Pseudocode for RL-based molecular generation\nfor episode in range(num_episodes):\n    state = env.reset()\n    done = False\n    while not done:\n        action = agent.select_action(state)\n        next_state, reward, done, _ = env.step(action)\n        agent.update(state, action, reward, next_state)\n        state = next_state\n# Reward = f(predicted_activity, drug_likeness, etc.)\nWorkflow Diagram:\n\n\n\n\n\nflowchart TD\n    A[Initialize Agent] --&gt; B[Generate Molecule Step-by-Step]\n    B --&gt; C[Evaluate Reward (Property, Activity)]\n    C --&gt; D[Update Policy]\n    D --&gt; B\n    C --&gt; E[Output Molecule if Reward High]\n\n\n\n\n\n\nFurther Reading: @reinvent @deep_rl_drug_design",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Conditional Generation</span>"
    ]
  },
  {
    "objectID": "chapters/chapter11-transformers-chemistry.html",
    "href": "chapters/chapter11-transformers-chemistry.html",
    "title": "15  Chapter 11: Transformers in Chemistry",
    "section": "",
    "text": "15.1 11.1 Introduction to Transformers\nTransformers have revolutionized sequence modeling and are now applied to chemistry. This chapter explores transformer architectures for SMILES, reaction prediction, and property modeling.\nTransformers are deep learning models based on self-attention mechanisms, originally developed for natural language processing (NLP). They excel at modeling long-range dependencies in sequential data and have become the foundation for state-of-the-art models in many domains.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Chapter 11: Transformers in Chemistry</span>"
    ]
  },
  {
    "objectID": "chapters/chapter11-transformers-chemistry.html#introduction-to-transformers",
    "href": "chapters/chapter11-transformers-chemistry.html#introduction-to-transformers",
    "title": "15  Chapter 11: Transformers in Chemistry",
    "section": "",
    "text": "Key Features:\n\nSelf-attention allows the model to weigh the importance of different parts of the input sequence.\nHighly parallelizable and scalable to large datasets.\nExamples: BERT, GPT, T5, and their chemistry adaptations.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Chapter 11: Transformers in Chemistry</span>"
    ]
  },
  {
    "objectID": "chapters/chapter11-transformers-chemistry.html#smiles-transformers",
    "href": "chapters/chapter11-transformers-chemistry.html#smiles-transformers",
    "title": "15  Chapter 11: Transformers in Chemistry",
    "section": "15.2 11.2 SMILES Transformers",
    "text": "15.2 11.2 SMILES Transformers\nSMILES (Simplified Molecular Input Line Entry System) strings are a common way to represent molecules as sequences. Transformers can be trained on SMILES data for various tasks:\n\nSMILES Language Modeling:\n\nLearn the syntax and structure of valid SMILES strings.\nEnable generative tasks such as de novo molecule generation.\n\nPretrained Models:\n\nChemBERTa, SMILES-BERT, and other transformer models pretrained on large chemical databases.\nCan be fine-tuned for downstream tasks like property prediction or reaction classification.\n\nExample (Conceptual):\n\nTokenize SMILES strings and train a transformer to predict the next token or reconstruct masked tokens.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Chapter 11: Transformers in Chemistry</span>"
    ]
  },
  {
    "objectID": "chapters/chapter11-transformers-chemistry.html#reaction-prediction",
    "href": "chapters/chapter11-transformers-chemistry.html#reaction-prediction",
    "title": "15  Chapter 11: Transformers in Chemistry",
    "section": "15.3 11.3 Reaction Prediction",
    "text": "15.3 11.3 Reaction Prediction\nTransformers are used to predict the outcomes of chemical reactions by modeling reactants and products as sequences.\n\nSequence-to-Sequence Models:\n\nEncode reactant SMILES and decode product SMILES.\nTrained on large reaction datasets (e.g., USPTO).\n\nApplications:\n\nForward reaction prediction: Given reactants, predict products.\nRetrosynthesis: Given a product, predict possible reactants.\n\nAdvantages:\n\nCapture complex reaction patterns and context.\nOutperform traditional rule-based systems in many cases.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Chapter 11: Transformers in Chemistry</span>"
    ]
  },
  {
    "objectID": "chapters/chapter11-transformers-chemistry.html#property-prediction",
    "href": "chapters/chapter11-transformers-chemistry.html#property-prediction",
    "title": "15  Chapter 11: Transformers in Chemistry",
    "section": "15.4 11.4 Property Prediction",
    "text": "15.4 11.4 Property Prediction\nTransformers can be fine-tuned to predict molecular properties from SMILES or graph representations.\n\nApproach:\n\nPretrain a transformer on large chemical datasets.\nFine-tune on labeled data for specific properties (e.g., solubility, toxicity, activity).\n\nBenefits:\n\nLeverage transfer learning for improved accuracy with limited labeled data.\nCapture subtle structure-property relationships.\n\nExample (Conceptual):\n\nUse a pretrained SMILES transformer to predict logP, binding affinity, or ADMET properties.",
    "crumbs": [
      "Part II: Machine Learning for Molecules",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Chapter 11: Transformers in Chemistry</span>"
    ]
  },
  {
    "objectID": "chapters/chapter12-protein-structure.html",
    "href": "chapters/chapter12-protein-structure.html",
    "title": "16  Chapter 12: Protein Structure",
    "section": "",
    "text": "16.1 12.1 Protein Structure Levels\nUnderstanding protein structure is key to structure-based drug design. This chapter covers protein structure basics, experimental methods, and computational prediction (e.g., AlphaFold).\nProteins have a hierarchical structure, each level contributing to their function:",
    "crumbs": [
      "Part III: Structure-Based Drug Design",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Chapter 12: Protein Structure</span>"
    ]
  },
  {
    "objectID": "chapters/chapter12-protein-structure.html#protein-structure-levels",
    "href": "chapters/chapter12-protein-structure.html#protein-structure-levels",
    "title": "16  Chapter 12: Protein Structure",
    "section": "",
    "text": "Primary Structure:\n\nLinear sequence of amino acids in a polypeptide chain.\nDetermines all higher levels of structure.\n\nSecondary Structure:\n\nLocal folding patterns stabilized by hydrogen bonds.\nCommon motifs: α-helices and β-sheets.\n\nTertiary Structure:\n\n3D arrangement of a single polypeptide chain, including side-chain interactions.\nStabilized by hydrophobic interactions, disulfide bonds, and ionic interactions.\n\nQuaternary Structure:\n\nAssembly of multiple polypeptide chains (subunits) into a functional protein complex.",
    "crumbs": [
      "Part III: Structure-Based Drug Design",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Chapter 12: Protein Structure</span>"
    ]
  },
  {
    "objectID": "chapters/chapter12-protein-structure.html#experimental-determination",
    "href": "chapters/chapter12-protein-structure.html#experimental-determination",
    "title": "16  Chapter 12: Protein Structure",
    "section": "16.2 12.2 Experimental Determination",
    "text": "16.2 12.2 Experimental Determination\nExperimental methods for determining protein structures include:\n\nX-ray Crystallography:\n\nMost common method for high-resolution structures.\nRequires crystallization of the protein.\n\nNuclear Magnetic Resonance (NMR) Spectroscopy:\n\nUsed for small to medium-sized proteins in solution.\nProvides information on protein dynamics.\n\nCryo-Electron Microscopy (Cryo-EM):\n\nSuitable for large complexes and membrane proteins.\nDoes not require crystallization; recent advances have improved resolution.",
    "crumbs": [
      "Part III: Structure-Based Drug Design",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Chapter 12: Protein Structure</span>"
    ]
  },
  {
    "objectID": "chapters/chapter12-protein-structure.html#structure-prediction-tools",
    "href": "chapters/chapter12-protein-structure.html#structure-prediction-tools",
    "title": "16  Chapter 12: Protein Structure",
    "section": "16.3 12.3 Structure Prediction Tools",
    "text": "16.3 12.3 Structure Prediction Tools\nComputational tools can predict protein structures when experimental data is unavailable:\n\nHomology Modeling:\n\nBuilds models based on similarity to known structures (templates).\nTools: SWISS-MODEL, MODELLER.\n\nAb Initio Prediction:\n\nPredicts structure from sequence alone, without templates.\nComputationally intensive; used for small proteins.\n\nAlphaFold:\n\nDeep learning-based tool from DeepMind.\nAchieves near-experimental accuracy for many proteins.\nAlphaFold Protein Structure Database",
    "crumbs": [
      "Part III: Structure-Based Drug Design",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Chapter 12: Protein Structure</span>"
    ]
  },
  {
    "objectID": "chapters/chapter12-protein-structure.html#protein-ligand-interactions",
    "href": "chapters/chapter12-protein-structure.html#protein-ligand-interactions",
    "title": "16  Chapter 12: Protein Structure",
    "section": "16.4 12.4 Protein-Ligand Interactions",
    "text": "16.4 12.4 Protein-Ligand Interactions\nUnderstanding how proteins interact with small molecules (ligands) is crucial for drug design:\n\nBinding Sites:\n\nSpecific regions on the protein where ligands bind.\nOften located in pockets or grooves on the protein surface.\n\nInteraction Types:\n\nHydrogen bonds, hydrophobic interactions, ionic bonds, van der Waals forces.\n\nDocking and Scoring:\n\nComputational docking predicts how ligands fit into binding sites.\nScoring functions estimate binding affinity.\n\nApplications:\n\nLead discovery, optimization, and understanding mechanism of action.",
    "crumbs": [
      "Part III: Structure-Based Drug Design",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Chapter 12: Protein Structure</span>"
    ]
  },
  {
    "objectID": "chapters/chapter13-molecular-docking.html",
    "href": "chapters/chapter13-molecular-docking.html",
    "title": "17  Chapter 13: Molecular Docking",
    "section": "",
    "text": "17.1 13.1 Docking Theory\nMolecular docking predicts how small molecules bind to protein targets. This chapter introduces docking theory, software, and practical workflows for virtual screening.\nDocking is a computational technique that predicts the preferred orientation of a small molecule (ligand) when bound to a protein (receptor). The goal is to estimate binding affinity and identify potential drug candidates.",
    "crumbs": [
      "Part III: Structure-Based Drug Design",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Chapter 13: Molecular Docking</span>"
    ]
  },
  {
    "objectID": "chapters/chapter13-molecular-docking.html#docking-theory",
    "href": "chapters/chapter13-molecular-docking.html#docking-theory",
    "title": "17  Chapter 13: Molecular Docking",
    "section": "",
    "text": "Key Concepts:\n\nSearch Algorithm: Explores possible ligand conformations and orientations in the binding site.\nScoring Function: Estimates the strength of the interaction (binding affinity) between ligand and protein.\nRigid vs. Flexible Docking: Rigid docking keeps the protein and ligand fixed; flexible docking allows movement in the ligand and/or protein.",
    "crumbs": [
      "Part III: Structure-Based Drug Design",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Chapter 13: Molecular Docking</span>"
    ]
  },
  {
    "objectID": "chapters/chapter13-molecular-docking.html#docking-software-autodock-vina",
    "href": "chapters/chapter13-molecular-docking.html#docking-software-autodock-vina",
    "title": "17  Chapter 13: Molecular Docking",
    "section": "17.2 13.2 Docking Software (AutoDock, Vina)",
    "text": "17.2 13.2 Docking Software (AutoDock, Vina)\nSeveral software packages are widely used for molecular docking:\n\nAutoDock:\n\nOne of the most popular open-source docking tools.\nUses Lamarckian genetic algorithm for conformational search.\nSupports flexible ligand and some flexible side-chain docking.\n\nAutoDock Vina:\n\nImproved version of AutoDock with faster performance and better scoring.\nUser-friendly and widely adopted for virtual screening.\n\nOther Tools:\n\nDOCK, GOLD, Glide, and others are also used in academia and industry.",
    "crumbs": [
      "Part III: Structure-Based Drug Design",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Chapter 13: Molecular Docking</span>"
    ]
  },
  {
    "objectID": "chapters/chapter13-molecular-docking.html#preparing-structures-for-docking",
    "href": "chapters/chapter13-molecular-docking.html#preparing-structures-for-docking",
    "title": "17  Chapter 13: Molecular Docking",
    "section": "17.3 13.3 Preparing Structures for Docking",
    "text": "17.3 13.3 Preparing Structures for Docking\nProper preparation of protein and ligand structures is critical for successful docking:\n\nProtein Preparation:\n\nRemove water molecules and irrelevant ligands.\nAdd missing atoms and assign correct protonation states.\nDefine the binding site (e.g., using known ligand or cavity detection).\n\nLigand Preparation:\n\nGenerate 3D conformations.\nAssign correct protonation and tautomeric states.\nMinimize energy to relieve strain.\n\nFile Formats:\n\nPDBQT (AutoDock/Vina), MOL2, SDF, PDB.",
    "crumbs": [
      "Part III: Structure-Based Drug Design",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Chapter 13: Molecular Docking</span>"
    ]
  },
  {
    "objectID": "chapters/chapter13-molecular-docking.html#analyzing-docking-results",
    "href": "chapters/chapter13-molecular-docking.html#analyzing-docking-results",
    "title": "17  Chapter 13: Molecular Docking",
    "section": "17.4 13.4 Analyzing Docking Results",
    "text": "17.4 13.4 Analyzing Docking Results\nAfter docking, results must be analyzed to identify promising candidates:\n\nScoring and Ranking:\n\nDocking software provides binding affinity scores for each pose.\nRank compounds based on scores, but consider limitations of scoring functions.\n\nVisual Inspection:\n\nUse molecular visualization tools (e.g., PyMOL, Chimera) to examine binding modes.\nCheck for key interactions (hydrogen bonds, hydrophobic contacts) and fit in the binding site.\n\nPost-Processing:\n\nCluster similar poses, filter by interaction criteria, and consider rescoring with more accurate methods if needed.\n\nExperimental Validation:\n\nTop candidates should be validated experimentally for biological activity.",
    "crumbs": [
      "Part III: Structure-Based Drug Design",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Chapter 13: Molecular Docking</span>"
    ]
  },
  {
    "objectID": "chapters/chapter14-ml-enhanced-docking.html",
    "href": "chapters/chapter14-ml-enhanced-docking.html",
    "title": "18  Chapter 14: ML-Enhanced Docking",
    "section": "",
    "text": "18.1 14.1 ML Scoring Functions\nMachine learning can improve docking accuracy and speed. This chapter discusses ML scoring functions, pose prediction, and integration with docking pipelines.\nTraditional docking scoring functions are based on physics or empirical rules. Machine learning (ML) scoring functions use data-driven models to predict binding affinity more accurately.",
    "crumbs": [
      "Part III: Structure-Based Drug Design",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Chapter 14: ML-Enhanced Docking</span>"
    ]
  },
  {
    "objectID": "chapters/chapter14-ml-enhanced-docking.html#ml-scoring-functions",
    "href": "chapters/chapter14-ml-enhanced-docking.html#ml-scoring-functions",
    "title": "18  Chapter 14: ML-Enhanced Docking",
    "section": "",
    "text": "Types of ML Scoring Functions:\n\nRegression Models: Predict binding affinity from features (e.g., random forests, gradient boosting, neural networks).\nDeep Learning Models: Use 3D protein-ligand structures as input (e.g., convolutional neural networks, graph neural networks).\n\nPopular ML Scoring Tools:\n\nRF-Score: Random forest model using atom pair features.\nDeltaVina: Combines ML with traditional Vina scoring.\nDeepDock, GNINA: Deep learning-based scoring using 3D grids or graphs.\n\nAdvantages:\n\nCapture complex, non-linear interactions.\nCan be retrained on new data for specific targets.",
    "crumbs": [
      "Part III: Structure-Based Drug Design",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Chapter 14: ML-Enhanced Docking</span>"
    ]
  },
  {
    "objectID": "chapters/chapter14-ml-enhanced-docking.html#pose-prediction",
    "href": "chapters/chapter14-ml-enhanced-docking.html#pose-prediction",
    "title": "18  Chapter 14: ML-Enhanced Docking",
    "section": "18.2 14.2 Pose Prediction",
    "text": "18.2 14.2 Pose Prediction\nML models can also predict the correct binding pose of a ligand in a protein binding site.\n\nPose Ranking:\n\nML models can re-rank docking poses generated by traditional software, improving the selection of the most likely binding mode.\n\nEnd-to-End Pose Prediction:\n\nSome deep learning models directly predict ligand poses from protein and ligand structures (e.g., EquiBind, DeepDock).\n\nEvaluation:\n\nRoot-mean-square deviation (RMSD) is used to assess pose accuracy compared to experimental structures.",
    "crumbs": [
      "Part III: Structure-Based Drug Design",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Chapter 14: ML-Enhanced Docking</span>"
    ]
  },
  {
    "objectID": "chapters/chapter14-ml-enhanced-docking.html#integrating-ml-with-docking",
    "href": "chapters/chapter14-ml-enhanced-docking.html#integrating-ml-with-docking",
    "title": "18  Chapter 14: ML-Enhanced Docking",
    "section": "18.3 14.3 Integrating ML with Docking",
    "text": "18.3 14.3 Integrating ML with Docking\nML can be integrated into docking pipelines to enhance virtual screening and lead optimization:\n\nHybrid Workflows:\n\nUse traditional docking to generate poses, then apply ML scoring for more accurate ranking.\nFilter large libraries with fast ML models before detailed docking.\n\nActive Learning:\n\nIteratively improve ML models by incorporating feedback from new docking or experimental results.\n\nAutomation:\n\nML models can automate hit selection, pose filtering, and prioritization in large-scale screens.\n\nExample Workflow:\n\nDock a library of compounds using AutoDock Vina.\nScore top poses with a deep learning model (e.g., GNINA).\nSelect candidates for experimental validation based on ML scores.",
    "crumbs": [
      "Part III: Structure-Based Drug Design",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Chapter 14: ML-Enhanced Docking</span>"
    ]
  },
  {
    "objectID": "chapters/chapter15-retrosynthesis.html",
    "href": "chapters/chapter15-retrosynthesis.html",
    "title": "19  Chapter 15: Retrosynthesis",
    "section": "",
    "text": "19.1 15.1 Introduction to Retrosynthesis\nRetrosynthesis planning is essential for proposing synthetic routes to molecules. This chapter covers rule-based and AI-driven retrosynthesis tools and strategies.\nRetrosynthesis is the process of deconstructing a target molecule into simpler precursor structures, working backward from the product to available starting materials. It is a key strategy in organic synthesis and drug development.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Chapter 15: Retrosynthesis</span>"
    ]
  },
  {
    "objectID": "chapters/chapter15-retrosynthesis.html#introduction-to-retrosynthesis",
    "href": "chapters/chapter15-retrosynthesis.html#introduction-to-retrosynthesis",
    "title": "19  Chapter 15: Retrosynthesis",
    "section": "",
    "text": "Key Concepts:\n\nIdentify strategic bonds to break (disconnections).\nPropose sequences of reactions to build the target molecule from simpler compounds.\nUse chemical knowledge, reaction databases, and computational tools.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Chapter 15: Retrosynthesis</span>"
    ]
  },
  {
    "objectID": "chapters/chapter15-retrosynthesis.html#rule-based-approaches",
    "href": "chapters/chapter15-retrosynthesis.html#rule-based-approaches",
    "title": "19  Chapter 15: Retrosynthesis",
    "section": "19.2 15.2 Rule-Based Approaches",
    "text": "19.2 15.2 Rule-Based Approaches\nRule-based retrosynthesis uses encoded chemical rules and reaction templates to suggest possible disconnections and synthetic routes.\n\nHow It Works:\n\nReaction rules are derived from known chemical transformations.\nThe system applies these rules recursively to break down the target molecule.\n\nPopular Tools:\n\nLHASA: One of the earliest expert systems for retrosynthesis.\nChematica (Synthia): Commercial platform with a large rule database.\nRDKit: Open-source cheminformatics toolkit with basic retrosynthesis capabilities.\n\nAdvantages:\n\nTransparent and interpretable routes.\nLeverages established chemical knowledge.\n\nLimitations:\n\nLimited by the coverage of encoded rules.\nMay miss novel or unconventional pathways.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Chapter 15: Retrosynthesis</span>"
    ]
  },
  {
    "objectID": "chapters/chapter15-retrosynthesis.html#ai-driven-retrosynthesis",
    "href": "chapters/chapter15-retrosynthesis.html#ai-driven-retrosynthesis",
    "title": "19  Chapter 15: Retrosynthesis",
    "section": "19.3 15.3 AI-Driven Retrosynthesis",
    "text": "19.3 15.3 AI-Driven Retrosynthesis\nAI-driven retrosynthesis uses machine learning and deep learning to predict synthetic routes, often learning directly from reaction databases.\n\nTemplate-Based Models:\n\nUse reaction templates extracted from data, similar to rule-based systems but with automated extraction and ranking.\n\nTemplate-Free Models:\n\nSequence-to-sequence (seq2seq) models treat retrosynthesis as a translation problem (product to reactants).\nGraph neural networks (GNNs) model molecular graphs for reaction prediction.\n\nPopular AI Tools:\n\nASKCOS: Open-source platform using neural networks for retrosynthesis.\nIBM RXN: Cloud-based AI retrosynthesis tool.\nAiZynthFinder: Open-source tool for automated retrosynthetic planning.\n\nAdvantages:\n\nCan generalize to novel reactions and pathways.\nContinuously improve with more data.\n\nLimitations:\n\nMay generate less interpretable routes.\nDependent on quality and diversity of training data.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Chapter 15: Retrosynthesis</span>"
    ]
  },
  {
    "objectID": "chapters/chapter15-retrosynthesis.html#evaluating-synthetic-routes",
    "href": "chapters/chapter15-retrosynthesis.html#evaluating-synthetic-routes",
    "title": "19  Chapter 15: Retrosynthesis",
    "section": "19.4 15.4 Evaluating Synthetic Routes",
    "text": "19.4 15.4 Evaluating Synthetic Routes\nEvaluating proposed synthetic routes is crucial for practical application:\n\nCriteria:\n\nNumber of steps (shorter is often better).\nAvailability and cost of starting materials.\nFeasibility and reliability of each reaction step.\nOverall yield and scalability.\n\nScoring and Ranking:\n\nMany tools provide scores based on route length, confidence, or synthetic accessibility.\n\nExperimental Validation:\n\nUltimately, routes must be tested in the lab to confirm feasibility.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Chapter 15: Retrosynthesis</span>"
    ]
  },
  {
    "objectID": "chapters/chapter16-multi-modal-learning.html",
    "href": "chapters/chapter16-multi-modal-learning.html",
    "title": "20  Chapter 16: Multi-Modal Learning",
    "section": "",
    "text": "20.1 16.1 What is Multi-Modal Learning?\nMulti-modal learning combines data types (e.g., chemical, biological, clinical) for improved predictions. This chapter explores architectures and applications in drug discovery.\nMulti-modal learning is a machine learning paradigm that integrates information from multiple data sources or modalities. In drug discovery, these modalities can include chemical structures, gene expression profiles, protein sequences, clinical data, and more.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Chapter 16: Multi-Modal Learning</span>"
    ]
  },
  {
    "objectID": "chapters/chapter16-multi-modal-learning.html#what-is-multi-modal-learning",
    "href": "chapters/chapter16-multi-modal-learning.html#what-is-multi-modal-learning",
    "title": "20  Chapter 16: Multi-Modal Learning",
    "section": "",
    "text": "Motivation:\n\nSingle data types may not capture the full complexity of biological systems.\nCombining modalities can improve prediction accuracy and provide deeper insights.\n\nExamples of Modalities:\n\nChemical: SMILES, molecular graphs, descriptors\nBiological: gene expression, protein sequences, omics data\nClinical: patient records, trial outcomes",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Chapter 16: Multi-Modal Learning</span>"
    ]
  },
  {
    "objectID": "chapters/chapter16-multi-modal-learning.html#data-integration-strategies",
    "href": "chapters/chapter16-multi-modal-learning.html#data-integration-strategies",
    "title": "20  Chapter 16: Multi-Modal Learning",
    "section": "20.2 16.2 Data Integration Strategies",
    "text": "20.2 16.2 Data Integration Strategies\nIntegrating diverse data types requires careful design of model architectures and data processing pipelines.\n\nEarly Fusion:\n\nConcatenate features from all modalities at the input layer.\nSimple but may not capture complex relationships.\n\nLate Fusion:\n\nTrain separate models for each modality, then combine predictions (e.g., averaging, stacking).\nUseful when modalities are very different in scale or type.\n\nHybrid/Intermediate Fusion:\n\nCombine intermediate representations from each modality within the model (e.g., via attention mechanisms or shared layers).\nAllows learning of cross-modal interactions.\n\nDeep Learning Architectures:\n\nMulti-branch neural networks, attention-based models, and graph neural networks can all be adapted for multi-modal integration.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Chapter 16: Multi-Modal Learning</span>"
    ]
  },
  {
    "objectID": "chapters/chapter16-multi-modal-learning.html#applications-in-drug-discovery",
    "href": "chapters/chapter16-multi-modal-learning.html#applications-in-drug-discovery",
    "title": "20  Chapter 16: Multi-Modal Learning",
    "section": "20.3 16.3 Applications in Drug Discovery",
    "text": "20.3 16.3 Applications in Drug Discovery\nMulti-modal learning is increasingly used in drug discovery to leverage the wealth of available data:\n\nDrug Response Prediction:\n\nCombine chemical structure and gene expression data to predict how cell lines or patients will respond to drugs.\n\nTarget Identification:\n\nIntegrate omics data, protein-protein interactions, and chemical information to identify new drug targets.\n\nAdverse Event Prediction:\n\nUse clinical records, molecular properties, and biological data to predict side effects or toxicity.\n\nPrecision Medicine:\n\nTailor drug recommendations by integrating patient-specific clinical and molecular data.\n\nExample (Conceptual):\n\nA multi-modal neural network takes SMILES strings, gene expression profiles, and patient data as input to predict drug efficacy for personalized treatment.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Chapter 16: Multi-Modal Learning</span>"
    ]
  },
  {
    "objectID": "chapters/chapter17-end-to-end-pipeline.html",
    "href": "chapters/chapter17-end-to-end-pipeline.html",
    "title": "21  Chapter 17: End-to-End Pipeline",
    "section": "",
    "text": "21.1 17.1 Pipeline Overview\nThis chapter presents a complete AI-driven drug discovery pipeline, from data collection to candidate prioritization, integrating methods from previous chapters.\nAn end-to-end AI-driven drug discovery pipeline integrates cheminformatics, machine learning, and structure-based methods to accelerate the identification of promising drug candidates.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Chapter 17: End-to-End Pipeline</span>"
    ]
  },
  {
    "objectID": "chapters/chapter17-end-to-end-pipeline.html#pipeline-overview",
    "href": "chapters/chapter17-end-to-end-pipeline.html#pipeline-overview",
    "title": "21  Chapter 17: End-to-End Pipeline",
    "section": "",
    "text": "Key Stages:\n\nData collection and curation\nFeature extraction and data preprocessing\nModel training and validation\nVirtual screening and candidate prioritization",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Chapter 17: End-to-End Pipeline</span>"
    ]
  },
  {
    "objectID": "chapters/chapter17-end-to-end-pipeline.html#data-preparation",
    "href": "chapters/chapter17-end-to-end-pipeline.html#data-preparation",
    "title": "21  Chapter 17: End-to-End Pipeline",
    "section": "21.2 17.2 Data Preparation",
    "text": "21.2 17.2 Data Preparation\nHigh-quality data is the foundation of any successful pipeline.\n\nData Sources:\n\nPublic databases (e.g., ChEMBL, PubChem, PDB)\nIn-house experimental data\n\nData Curation:\n\nRemove duplicates, standardize chemical structures, and handle missing values.\nAnnotate data with relevant properties (e.g., activity, ADMET, target information).\n\nFeature Engineering:\n\nGenerate molecular fingerprints, descriptors, and graph representations.\nIntegrate multi-modal data (e.g., chemical, biological, clinical).",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Chapter 17: End-to-End Pipeline</span>"
    ]
  },
  {
    "objectID": "chapters/chapter17-end-to-end-pipeline.html#model-training-and-evaluation",
    "href": "chapters/chapter17-end-to-end-pipeline.html#model-training-and-evaluation",
    "title": "21  Chapter 17: End-to-End Pipeline",
    "section": "21.3 17.3 Model Training and Evaluation",
    "text": "21.3 17.3 Model Training and Evaluation\nMachine learning models are trained to predict properties such as bioactivity, ADMET, or binding affinity.\n\nModel Selection:\n\nChoose appropriate algorithms (e.g., random forests, deep neural networks, graph neural networks, transformers).\n\nTraining:\n\nSplit data into training, validation, and test sets.\nOptimize hyperparameters and prevent overfitting.\n\nEvaluation:\n\nUse metrics such as ROC-AUC, RMSE, accuracy, and F1-score.\nPerform cross-validation and external validation if possible.\n\nInterpretability:\n\nAnalyze feature importance and model explanations to gain insights.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Chapter 17: End-to-End Pipeline</span>"
    ]
  },
  {
    "objectID": "chapters/chapter17-end-to-end-pipeline.html#candidate-selection",
    "href": "chapters/chapter17-end-to-end-pipeline.html#candidate-selection",
    "title": "21  Chapter 17: End-to-End Pipeline",
    "section": "21.4 17.4 Candidate Selection",
    "text": "21.4 17.4 Candidate Selection\nThe final stage is to prioritize candidates for experimental validation.\n\nVirtual Screening:\n\nScreen large compound libraries using trained models and/or docking.\nRank compounds based on predicted activity, ADMET, and synthetic accessibility.\n\nFiltering:\n\nApply property-based and rule-based filters (e.g., Lipinski’s rules, toxicity filters).\n\nMulti-Parameter Optimization:\n\nBalance potency, selectivity, safety, and developability.\n\nExperimental Validation:\n\nSelect top candidates for synthesis and biological testing.\n\nIterative Improvement:\n\nIncorporate new data and feedback to refine models and repeat the pipeline.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Chapter 17: End-to-End Pipeline</span>"
    ]
  },
  {
    "objectID": "chapters/chapter18-case-studies.html",
    "href": "chapters/chapter18-case-studies.html",
    "title": "22  Chapter 18: Case Studies",
    "section": "",
    "text": "22.1 18.1 Case Study 1: ALS Drug Discovery\nReal-world case studies demonstrate the application of AI and cheminformatics in drug discovery. This chapter presents selected examples and lessons learned.\nBackground: Amyotrophic lateral sclerosis (ALS) is a neurodegenerative disease with limited treatment options. AI-driven approaches have been used to identify new therapeutic candidates.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Chapter 18: Case Studies</span>"
    ]
  },
  {
    "objectID": "chapters/chapter18-case-studies.html#case-study-1-als-drug-discovery",
    "href": "chapters/chapter18-case-studies.html#case-study-1-als-drug-discovery",
    "title": "22  Chapter 18: Case Studies",
    "section": "",
    "text": "Data Collection:\n\nIntegrated omics data, literature mining, and known ALS-related targets.\nUsed cheminformatics to curate compound libraries for screening.\n\nVirtual Screening:\n\nApplied machine learning models to predict neuroprotective activity.\nUsed molecular docking to prioritize compounds for SOD1 and TDP-43 protein targets.\n\nExperimental Validation:\n\nTop candidates were tested in cell-based assays for neuroprotection.\n\nOutcome:\n\nIdentified several promising compounds for further development.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Chapter 18: Case Studies</span>"
    ]
  },
  {
    "objectID": "chapters/chapter18-case-studies.html#case-study-2-kinase-inhibitors",
    "href": "chapters/chapter18-case-studies.html#case-study-2-kinase-inhibitors",
    "title": "22  Chapter 18: Case Studies",
    "section": "22.2 18.2 Case Study 2: Kinase Inhibitors",
    "text": "22.2 18.2 Case Study 2: Kinase Inhibitors\nBackground: Kinases are important drug targets in cancer and other diseases. AI and cheminformatics have accelerated the discovery of selective kinase inhibitors.\n\nData Integration:\n\nCombined chemical structure data, kinase activity profiles, and protein-ligand interaction data.\n\nQSAR Modeling:\n\nBuilt machine learning models to predict kinase inhibition based on molecular fingerprints and descriptors.\n\nStructure-Based Design:\n\nUsed docking and molecular dynamics to optimize binding affinity and selectivity.\n\nLead Optimization:\n\nApplied multi-parameter optimization to balance potency, selectivity, and ADMET properties.\n\nOutcome:\n\nAccelerated identification of novel kinase inhibitors with improved profiles.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Chapter 18: Case Studies</span>"
    ]
  },
  {
    "objectID": "chapters/chapter18-case-studies.html#lessons-learned",
    "href": "chapters/chapter18-case-studies.html#lessons-learned",
    "title": "22  Chapter 18: Case Studies",
    "section": "22.3 18.3 Lessons Learned",
    "text": "22.3 18.3 Lessons Learned\n\nData Quality Matters:\n\nHigh-quality, well-curated data is essential for successful AI-driven drug discovery.\n\nIntegration is Key:\n\nCombining multiple data types and methods yields better results than using a single approach.\n\nIterative Process:\n\nDrug discovery is iterative—models and hypotheses should be refined as new data becomes available.\n\nCollaboration:\n\nSuccess often requires collaboration between computational scientists, chemists, and biologists.\n\nLimitations:\n\nAI models are only as good as their training data and may not generalize to novel targets or chemotypes.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Chapter 18: Case Studies</span>"
    ]
  },
  {
    "objectID": "chapters/chapter19-external-tools.html",
    "href": "chapters/chapter19-external-tools.html",
    "title": "23  Chapter 19: External Tools",
    "section": "",
    "text": "23.1 19.1 Structural Databases\nThis chapter reviews external tools and databases commonly used in computational drug discovery, including RCSB PDB, ChEMBL, and PubChem.\nStructural databases provide 3D structures of proteins, nucleic acids, and complexes, which are essential for structure-based drug design.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Chapter 19: External Tools</span>"
    ]
  },
  {
    "objectID": "chapters/chapter19-external-tools.html#structural-databases",
    "href": "chapters/chapter19-external-tools.html#structural-databases",
    "title": "23  Chapter 19: External Tools",
    "section": "",
    "text": "RCSB Protein Data Bank (PDB):\n\nThe primary repository for experimentally determined 3D structures of biological macromolecules.\nrcsb.org\nStructures are available in PDB and mmCIF formats.\n\nAlphaFold Protein Structure Database:\n\nProvides predicted protein structures using deep learning.\nalphafold.ebi.ac.uk\n\nOther Databases:\n\nPDB-REDO (refined structures), CATH/SCOP (structure classification).",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Chapter 19: External Tools</span>"
    ]
  },
  {
    "objectID": "chapters/chapter19-external-tools.html#bioactivity-databases",
    "href": "chapters/chapter19-external-tools.html#bioactivity-databases",
    "title": "23  Chapter 19: External Tools",
    "section": "23.2 19.2 Bioactivity Databases",
    "text": "23.2 19.2 Bioactivity Databases\nBioactivity databases contain information on small molecules, their biological activities, and targets.\n\nChEMBL:\n\nA large, open-access database of bioactive molecules with drug-like properties.\nIncludes activity data (IC50, Ki, etc.), targets, and assay information.\nebi.ac.uk/chembl\n\nPubChem:\n\nComprehensive resource for chemical structures, properties, and biological activities.\nIncludes compound, substance, and bioassay databases.\npubchem.ncbi.nlm.nih.gov\n\nBindingDB:\n\nFocuses on binding affinities for protein-ligand complexes.\nbindingdb.org",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Chapter 19: External Tools</span>"
    ]
  },
  {
    "objectID": "chapters/chapter19-external-tools.html#workflow-automation-tools",
    "href": "chapters/chapter19-external-tools.html#workflow-automation-tools",
    "title": "23  Chapter 19: External Tools",
    "section": "23.3 19.3 Workflow Automation Tools",
    "text": "23.3 19.3 Workflow Automation Tools\nWorkflow automation tools streamline computational drug discovery by integrating multiple steps and tools into reproducible pipelines.\n\nKNIME:\n\nOpen-source platform for data analytics and workflow automation.\nWidely used for cheminformatics, bioinformatics, and machine learning workflows.\nknime.com\n\nPipeline Pilot:\n\nCommercial workflow automation tool for scientific data processing.\nSupports cheminformatics, bioinformatics, and analytics.\n\nGalaxy:\n\nWeb-based platform for accessible, reproducible, and transparent computational research.\nusegalaxy.org\n\nSnakemake/Nextflow:\n\nWorkflow management systems for scalable and reproducible data analysis pipelines.\n\nIntegration with Scripting:\n\nPython, R, and shell scripts are often used to glue together custom workflows.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Chapter 19: External Tools</span>"
    ]
  },
  {
    "objectID": "chapters/chapter20-ethical-considerations.html",
    "href": "chapters/chapter20-ethical-considerations.html",
    "title": "24  Chapter 20: Ethical Considerations",
    "section": "",
    "text": "24.1 20.1 Data Privacy and Security\nEthics are critical in AI-driven drug discovery. This chapter discusses data privacy, algorithmic bias, and responsible innovation in cheminformatics and AI.\nProtecting sensitive data is essential in drug discovery, especially when working with patient information, proprietary compounds, or clinical trial data.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Chapter 20: Ethical Considerations</span>"
    ]
  },
  {
    "objectID": "chapters/chapter20-ethical-considerations.html#data-privacy-and-security",
    "href": "chapters/chapter20-ethical-considerations.html#data-privacy-and-security",
    "title": "24  Chapter 20: Ethical Considerations",
    "section": "",
    "text": "Data Privacy:\n\nEnsure compliance with regulations (e.g., GDPR, HIPAA) when handling personal or health data.\nUse anonymization and de-identification techniques to protect individual identities.\n\nData Security:\n\nImplement robust cybersecurity measures to prevent unauthorized access or data breaches.\nUse secure data storage, encrypted communication, and access controls.\n\nData Sharing:\n\nBalance open science with the need to protect sensitive or proprietary information.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Chapter 20: Ethical Considerations</span>"
    ]
  },
  {
    "objectID": "chapters/chapter20-ethical-considerations.html#bias-in-ai-models",
    "href": "chapters/chapter20-ethical-considerations.html#bias-in-ai-models",
    "title": "24  Chapter 20: Ethical Considerations",
    "section": "24.2 20.2 Bias in AI Models",
    "text": "24.2 20.2 Bias in AI Models\nAI models can inherit or amplify biases present in training data, leading to unfair or inaccurate predictions.\n\nSources of Bias:\n\nImbalanced datasets (e.g., overrepresentation of certain chemotypes or populations).\nHistorical biases in experimental data or reporting.\n\nConsequences:\n\nReduced model performance for underrepresented groups or rare targets.\nPotential for inequitable healthcare outcomes.\n\nMitigation Strategies:\n\nUse diverse and representative datasets.\nApply fairness-aware algorithms and regular audits for bias.\nTransparently report model limitations and performance across subgroups.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Chapter 20: Ethical Considerations</span>"
    ]
  },
  {
    "objectID": "chapters/chapter20-ethical-considerations.html#responsible-innovation",
    "href": "chapters/chapter20-ethical-considerations.html#responsible-innovation",
    "title": "24  Chapter 20: Ethical Considerations",
    "section": "24.3 20.3 Responsible Innovation",
    "text": "24.3 20.3 Responsible Innovation\nResponsible innovation ensures that AI and cheminformatics tools are developed and used in ways that benefit society and minimize harm.\n\nTransparency:\n\nMake model architectures, training data, and evaluation metrics publicly available when possible.\n\nAccountability:\n\nClearly define responsibility for model predictions and decisions, especially in clinical settings.\n\nSocietal Impact:\n\nConsider the broader implications of AI-driven drug discovery, such as access to medicines, dual-use risks, and environmental impact.\n\nContinuous Oversight:\n\nEngage stakeholders (scientists, ethicists, patients, regulators) throughout the development and deployment process.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Chapter 20: Ethical Considerations</span>"
    ]
  },
  {
    "objectID": "chapters/chapter21-future-next-steps.html",
    "href": "chapters/chapter21-future-next-steps.html",
    "title": "25  Chapter 21: Future Next Steps",
    "section": "",
    "text": "25.1 21.1 Emerging Technologies\nThe final chapter outlines emerging trends and future directions in AI-driven drug discovery, including new algorithms, data sources, and collaborative science.\nAI-driven drug discovery is rapidly evolving, with several emerging technologies poised to transform the field:",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Chapter 21: Future Next Steps</span>"
    ]
  },
  {
    "objectID": "chapters/chapter21-future-next-steps.html#emerging-technologies",
    "href": "chapters/chapter21-future-next-steps.html#emerging-technologies",
    "title": "25  Chapter 21: Future Next Steps",
    "section": "",
    "text": "Foundation Models and Large Language Models:\n\nUse of large pretrained models (e.g., ChemBERTa, MolBERT, GPT-4) for molecular design, property prediction, and literature mining.\n\nGenerative AI for Molecule Design:\n\nAdvanced generative models (e.g., diffusion models, graph-based VAEs) for de novo compound generation.\n\nMulti-Omics Integration:\n\nCombining genomics, proteomics, metabolomics, and clinical data for holistic drug discovery.\n\nQuantum Computing:\n\nPotential to revolutionize molecular simulation and optimization tasks.\n\nAutomated Laboratories (Lab Automation):\n\nIntegration of robotics, AI, and cloud labs for high-throughput synthesis and testing.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Chapter 21: Future Next Steps</span>"
    ]
  },
  {
    "objectID": "chapters/chapter21-future-next-steps.html#open-science-and-collaboration",
    "href": "chapters/chapter21-future-next-steps.html#open-science-and-collaboration",
    "title": "25  Chapter 21: Future Next Steps",
    "section": "25.2 21.2 Open Science and Collaboration",
    "text": "25.2 21.2 Open Science and Collaboration\nOpen science and collaborative efforts are accelerating progress in drug discovery:\n\nOpen Data Initiatives:\n\nPublic databases (e.g., ChEMBL, PubChem, PDB) and open-access datasets fuel innovation.\n\nOpen-Source Software:\n\nCommunity-driven tools (e.g., RDKit, DeepChem, OpenMM) enable reproducible research.\n\nCollaborative Platforms:\n\nCrowdsourcing challenges (e.g., DREAM, Kaggle) and collaborative consortia (e.g., Open Targets, MELLODDY) bring together diverse expertise.\n\nPreprints and Open Publishing:\n\nRapid dissemination of new findings and methods.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Chapter 21: Future Next Steps</span>"
    ]
  },
  {
    "objectID": "chapters/chapter21-future-next-steps.html#next-steps-for-practitioners",
    "href": "chapters/chapter21-future-next-steps.html#next-steps-for-practitioners",
    "title": "25  Chapter 21: Future Next Steps",
    "section": "25.3 21.3 Next Steps for Practitioners",
    "text": "25.3 21.3 Next Steps for Practitioners\nFor those looking to advance in AI-driven drug discovery, consider the following steps:\n\nContinuous Learning:\n\nStay updated with the latest research, tools, and best practices.\nParticipate in workshops, online courses, and conferences.\n\nHands-On Practice:\n\nApply methods from this book to real-world datasets and problems.\nContribute to open-source projects and collaborative research.\n\nEthical and Responsible Innovation:\n\nPrioritize transparency, fairness, and societal impact in your work.\n\nNetworking and Collaboration:\n\nBuild connections with researchers, clinicians, and industry professionals.\n\nEmbrace Interdisciplinarity:\n\nCombine expertise in chemistry, biology, data science, and AI for maximum impact.",
    "crumbs": [
      "Part IV: Synthesis and Advanced Topics",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Chapter 21: Future Next Steps</span>"
    ]
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "26  Conclusion",
    "section": "",
    "text": "27 Conclusion\nYou have completed “AI-Driven Drug Discovery: A Hands-On Guide.” We hope you now feel equipped to apply AI and computational tools to real-world drug discovery challenges. Continue exploring, building, and contributing to this exciting field!",
    "crumbs": [
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "The following references are cited throughout this book:\n\nXiang Li Zhang. “Drug Discovery AI Assistant: End-to-End Modular System for Biomedical Research.” GitHub, 2025. https://github.com/justin-mbca/drug-discovery-ai\nLandrum, G. “RDKit: Open-source cheminformatics.” https://www.rdkit.org\nLipinski, C. A., et al. “Experimental and computational approaches to estimate solubility and permeability in drug discovery and development settings.” Adv Drug Deliv Rev, 2001. https://doi.org/10.1016/S0169-409X(00)00129-0\nChen, H., et al. “The rise of deep learning in drug discovery.” Drug Discovery Today, 2018. https://doi.org/10.1016/j.drudis.2018.01.039\nLee, J., et al. “BioBERT: a pre-trained biomedical language representation model for biomedical text mining.” Bioinformatics, 2020. https://doi.org/10.1093/bioinformatics/btz682\nWalters, W. P., et al. “Virtual screening—an overview.” Drug Discovery Today, 1998. https://doi.org/10.1016/S1359-6446(98)01202-2\nOpen Targets Platform. https://www.targetvalidation.org\nUniProt Consortium. “UniProt: a worldwide hub of protein knowledge.” Nucleic Acids Res, 2021. https://www.uniprot.org\nGaulton, A., et al. “ChEMBL: a large-scale bioactivity database for drug discovery.” Nucleic Acids Res, 2012. https://www.ebi.ac.uk/chembl/\nBerman, H. M., et al. “The Protein Data Bank.” Nucleic Acids Res, 2000. https://www.rcsb.org\nKim, S., et al. “PubChem in 2021: new data content and improved web interfaces.” Nucleic Acids Res, 2021. https://pubchem.ncbi.nlm.nih.gov\nPedregosa, F., et al. “Scikit-learn: Machine Learning in Python.” JMLR, 2011. https://scikit-learn.org\nPolykovskiy, D., et al. “Molecular Sets (MOSES): A Benchmarking Platform for Molecular Generation Models.” arXiv:1811.12823. https://arxiv.org/abs/1811.12823\nDe Cao, N., Kipf, T. “MolGAN: An implicit generative model for small molecular graphs.” arXiv:1805.11973. https://arxiv.org/abs/1805.11973\nSanchez-Lengeling, B., et al. “Optimizing distributions over molecular space. An objective-reinforced generative adversarial network for inverse-design chemistry (ORGAN).” J Chem Inf Model, 2017. https://doi.org/10.1021/acs.jcim.7b00690\nOlivecrona, M., et al. “Molecular de-novo design through deep reinforcement learning.” J Cheminform, 2017. https://doi.org/10.1186/s13321-017-0235-x\nZhou, Z., et al. “Optimization of molecules via deep reinforcement learning.” Sci Rep, 2019. https://doi.org/10.1038/s41598-019-47148-x\nKanehisa, M., et al. “KEGG: integrating viruses and cellular organisms.” Nucleic Acids Res, 2021.\nJumper, J., et al. “Highly accurate protein structure prediction with AlphaFold.” Nature, 2021.\nHamilton, W. L., et al. “Representation Learning on Graphs: Methods and Applications.” IEEE Data Eng Bull, 2017.\nStokes, J. M., et al. “A deep learning approach to antibiotic discovery.” Cell, 2020.\nZhang, S., et al. “Graph Neural Networks: A Review of Methods and Applications.” AI Open, 2021.\nVamathevan, J., et al. “Applications of machine learning in drug discovery and development.” Nat Rev Drug Discov, 2019.\nCrewAI. https://github.com/joaomdmoura/crewAI\nWolf, T., et al. “Transformers: State-of-the-Art Natural Language Processing.” EMNLP, 2020.\n\n\n\n\n\nFurther Reading\n\nCrewAI\nTransformers: State-of-the-Art NLP (Wolf et al., 2020)\nMultiagent systems: Algorithmic, game-theoretic, and logical foundations (Shoham et al., 2009) @gnn_review: Wu, Z., et al. “A Comprehensive Survey on Graph Neural Networks.” IEEE Trans Neural Netw Learn Syst, 2021. @multiagent_review: Shoham, Y., et al. “Multiagent systems: Algorithmic, game-theoretic, and logical foundations.” Cambridge University Press, 2009.",
    "crumbs": [
      "References"
    ]
  }
]